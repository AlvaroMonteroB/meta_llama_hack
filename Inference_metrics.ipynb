{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqM-T1RTzY6C"
   },
   "source": [
    "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
    "<div class=\"align-center\">\n",
    "  <a href=\"https://github.com/unslothai/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
    "  <a href=\"https://discord.gg/u54VK8m8tk\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
    "  <a href=\"https://ko-fi.com/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Kofi button.png\" width=\"145\"></a></a> Join Discord if you need help + ⭐ <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ⭐\n",
    "</div>\n",
    "\n",
    "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://github.com/unslothai/unsloth?tab=readme-ov-file#-installation-instructions).\n",
    "\n",
    "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save) (eg for Llama.cpp).\n",
    "\n",
    "**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**\n",
    "\n",
    "Features in the notebook:\n",
    "1. Uses Maxime Labonne's [FineTome 100K](https://huggingface.co/datasets/mlabonne/FineTome-100k) dataset.\n",
    "1. Convert ShareGPT to HuggingFace format via `standardize_sharegpt`\n",
    "2. Train on Completions / Assistant only via `train_on_responses_only`\n",
    "3. Unsloth now supports Torch 2.4, all TRL & Xformers versions & Python 3.12!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2eSvM9zX_2d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unsloth in /usr/local/lib/python3.10/dist-packages (2024.10.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Found existing installation: unsloth 2024.10.3\n",
      "Uninstalling unsloth-2024.10.3:\n",
      "  Successfully uninstalled unsloth-2024.10.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git\n",
      "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-m8w3ulkw/unsloth_4d007f8437474ee68cf83f53a8e8013f\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-m8w3ulkw/unsloth_4d007f8437474ee68cf83f53a8e8013f\n",
      "  Resolved https://github.com/unslothai/unsloth.git to commit 1f52468fa31bf0b641ec96217ef0f5916a07fce5\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: unsloth-zoo in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.10.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (23.2)\n",
      "Requirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.8.13)\n",
      "Requirement already satisfied: transformers>=4.44.2 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.44.2)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.1)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.5)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.6)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.42.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.2)\n",
      "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.26.0)\n",
      "Requirement already satisfied: hf-transfer in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.8)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10.10)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.8.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.44.2->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.44.2->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.44.2->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.19.1)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.9.2)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.7.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.1)\n",
      "Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.0.1)\n",
      "Requirement already satisfied: trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.11.1,>=0.7.9 in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.11.1)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.13.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.15.5)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.11.17)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.17.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->unsloth-zoo->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
      "Building wheels for collected packages: unsloth\n",
      "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for unsloth: filename=unsloth-2024.10.3-py3-none-any.whl size=162561 sha256=037d9a51726db4a7d393968dd7bb5c3627b4c65a044b8dbb9b7a2e7a185ef3ab\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4j6v0k6h/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\n",
      "Successfully built unsloth\n",
      "Installing collected packages: unsloth\n",
      "Successfully installed unsloth-2024.10.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install unsloth\n",
    "# Also get the latest nightly Unsloth!\n",
    "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2v_X2fA0Df5"
   },
   "source": [
    "* We support Llama, Mistral, Phi-3, Gemma, Yi, DeepSeek, Qwen, TinyLlama, Vicuna, Open Hermes etc\n",
    "* We support 16bit LoRA or 4bit QLoRA. Both 2x faster.\n",
    "* `max_seq_length` can be set to anything, since we do automatic RoPE Scaling via [kaiokendev's](https://kaiokendev.github.io/til) method.\n",
    "* [**NEW**] We make Gemma-2 9b / 27b **2x faster**! See our [Gemma-2 9b notebook](https://colab.research.google.com/drive/1vIrqH5uYDQwsJ4-OO3DErvuv4pBgVwk4?usp=sharing)\n",
    "* [**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379,
     "referenced_widgets": [
      "8a94a101c0dc4422ac84cb8763cb566b",
      "f0aa09690fef4143aca13913f44cfee1",
      "754931fc0cc2433091ba1a8579ff2e14",
      "4f54ae54d9d24b8ea27b5828d73449bd",
      "fcf7564dd7004e46ba3b56fbea0480f6",
      "6188db144400485285a38317454bb19b",
      "027f7ba29d494073ad7ee49ae01dbc23",
      "8c06a5b3a3044fa9abae49f84e852b9c",
      "32f46fe8a5964432846decb0a1ef6c7f",
      "f6c902674fdf4f5d982129501c4ef36f",
      "fbb78609b507419f94e659f45551c3b8",
      "ad9bb2cae0d34b94820e2ec5b7f288d7",
      "89e7055e72b042609eab0eed86be1bba",
      "4ee9752e7c974f1c9fa57d63defd0273",
      "4f542ca725fc45b1a48a163fcb6da4a6",
      "d21149abf49c4c1e988e0686183a4f42",
      "091bc142327b49fdbba6d695641ed587",
      "b61fbeaa189347418a7bbc6d643b8103",
      "fb0ebba652e54e698f72c561b9aadb16",
      "765d4bf8045742068279650d8e25335a",
      "6ab0bfe025f84cf7ac7553806f7188ac",
      "767aafdb45d143368ccca8ac4e8c47de",
      "7597f82c689f4b07984176113d6db56a",
      "bc9b7de3b86e4aed9d1da38e854371c1",
      "a2f59b00a353431e931b726e4e4bd96c",
      "4ef0bbd8aa044edb850bebfb858fc3e2",
      "ddda6e01f229454fa176f2846a76b57e",
      "5866b9746e034c2dac999b2c3251bdfb",
      "93f0dc2041fc4053b947c5abfe091bf7",
      "cba5cfa885214c63a6b4f25253080ef8",
      "8b36cff4b3f94bfd8f071eba996e442d",
      "76f2765585ce450881cae910e442d664",
      "88792d090d824d1c8ff9207a2b69a1d4",
      "db97b6f6ddea440fb1a132dabd55e657",
      "571a5352d5824edba4bda40f4745fcea",
      "460de3366aa14a4f919b2bbc8ec9253b",
      "89e75bfd2e7443a9b09827d9c35642e8",
      "a35baa79dc464bf2b77398a6d40d3e18",
      "4d1739c429e1461db5520228f59d8e3a",
      "ee5e0354314e4ffda397d534a89770b6",
      "099625ffae9846be87f68b3649b6c838",
      "fa5ec7baf8344b34800984accedd32c3",
      "58955b380e6e480f9f1389d4946a8547",
      "f9c315759ff04bd4b25502a27de9cd9e",
      "bb96ef3138e2495a83f2d247f41d20f8",
      "2cac19210c9a48e5ae2c4bdb95837cd2",
      "7a9331d27e1343688c3743375e2926a3",
      "3ec446278d744d88b9dbdc3afeb5e582",
      "d6a3504cd4bb4855b9b1c9bdfe8c4ba0",
      "61ca62aa9988427294343613050e8301",
      "6fc8487d56a84c29a95ac506516c2b64",
      "d86e034517624b77a96dc91abb8630f7",
      "1550ee2d3de64537b726e30154f53bce",
      "7a459ea2df874a8194025f2715e92bc8",
      "a159738bb1034fa290a37ff107b03c27"
     ]
    },
    "id": "QmUBVEnvCDJv",
    "outputId": "f72ebc03-82ec-4679-d259-a3b2f818096c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth 2024.10.3: Fast Llama patching. Transformers = 4.44.2.\n",
      "   \\\\   /|    GPU: NVIDIA H100 NVL. Max memory: 93.122 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.1+cu121. CUDA = 9.0. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = False # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
    "fourbit_models = [\n",
    "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 2x faster\n",
    "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
    "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # 4bit for 405b!\n",
    "    \"unsloth/Mistral-Small-Instruct-2409\",     # Mistral 22b 2x faster!\n",
    "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
    "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
    "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
    "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
    "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
    "\n",
    "    \"unsloth/Llama-3.2-1B-bnb-4bit\",           # NEW! Llama 3.2 models\n",
    "    \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Llama-3.2-3B-bnb-4bit\",\n",
    "    \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"model2\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    load_in_8bit=False,\n",
    "    trust_remote_code=True\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXd9bTZd1aaL"
   },
   "source": [
    "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bZsfBuZDeCL",
    "outputId": "834ea61b-89df-40ac-ddcc-8cdfe1972094"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.10.3 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idAEIeSQ3xdS"
   },
   "source": [
    "<a name=\"Train\"></a>\n",
    "### Train the model\n",
    "Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Hya7fu0ONBA2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6677e85f4d649e487d131736b374d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "data_path=\"dataset.csv\"\n",
    "corpus=load_dataset('csv', data_files=data_path,column_names=['instruct', 'input', 'output'],cache_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IHh7b0J8O4WK",
    "outputId": "f4fd892c-b637-4c98-ad42-ed19baa561a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['instruct', 'input', 'output'],\n",
      "        num_rows: 21084\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "c483bd392fa643db8df04f41dd565601",
      "39266f36fbed42a28837c5964a4348d2",
      "e6f68ca87e5a4860878c69a1692eff8c",
      "d4a8a268f8014eda83c4e50aad7ac42c",
      "e1a821a2ffa9414aa4bf7c6e32b46b9e",
      "2d5a3e9844e64a28b410cb32143b8147",
      "824ae29b7b85472192b2d57ba9835d68",
      "afd8093f65034bce828d34329e4dd442",
      "7418ecc0016c476781399a0db9a7863f",
      "cb8b4795ae82477c92d48fcbd0004dd7",
      "023eff5ca8f84904b4211d59458df8de"
     ]
    },
    "id": "oZfeDhFvN7jP",
    "outputId": "7c7c2326-67d4-42f5-a254-4a0f7af93c61"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f60f3bafda8341558225c850bae33d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21084 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "def formatting_prompts_func(examples):\n",
    "  instructions = examples[\"instruct\"]\n",
    "  inputs = examples[\"input\"]\n",
    "  outputs = examples[\"output\"]\n",
    "  texts = []\n",
    "  for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "    text = instruction + \" \" + input + \" \" + output + EOS_TOKEN\n",
    "    texts.append(text)\n",
    "  return {\"text\":texts}\n",
    "\n",
    "dataset = corpus.map(formatting_prompts_func, batched = True, keep_in_memory=False, num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117,
     "referenced_widgets": [
      "1c7ccad9c9fa46a5b433f24c8173c727",
      "f5a55aa3b8964bbcb602b2656286801b",
      "74011c42474f496bbac9fbde8684fd00",
      "7b6aa54e66bb491b88bb8bbd634064c4",
      "74747322bb8a49edae82904fe24370b4",
      "cff85b3c1f51411b850894aed973afba",
      "9a0d9cca01e349ed94fb6515fdf236d0",
      "34331f790f3d4a98b34ac22dabc13a69",
      "1bd9fbb89ddb49ae92c3a13ffc76cbef",
      "a6f684f4839642768216fa453e6d2d61",
      "169a834157484941be504adfe5b731d7",
      "1f642765247b4b4ebabf021dc3af5ae9",
      "f1a9c88f77d746daae04cb2f306bcbed",
      "f82ae39e0302414a84ad1c5eedfd0232",
      "112132ae410a40e188a25d968f8ac659",
      "4d24b48da3fa47008c6fce46fe6e3f6c",
      "b186a04d94c64c8fad6248251fff69d6",
      "d58a9ae1ee144a5d84ca23e26a1d20e6",
      "c3622339b4ac4c81ba242c3ae561a8d9",
      "cdf3d68b36d74b4c80fd7856a2cd206d",
      "8179f044fd7b46aeaa30d71fa19419f8",
      "e42e3136e67444789888ef98f3debe19"
     ]
    },
    "id": "95_Nn-89DhsL",
    "outputId": "8e1d7309-ce94-462f-b1bd-176f745164e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Already have LoRA adapters! We shall skip this step.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae38c850322e4fa69e6734f1430fa8e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21084 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5064920264cd49d087a10702fe6f4916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21084 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
    "from unsloth import is_bfloat16_supported\n",
    "from unsloth import FastLanguageModel\n",
    "from datasets import Dataset\n",
    "\n",
    "# Configuración del modelo con LoRA\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,  # Puedes ajustar este valor (sugerido: 8, 16, 32, 64, 128)\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,  # 0 es optimizado\n",
    "    bias=\"none\",  # \"none\" es optimizado\n",
    "    use_gradient_checkpointing=\"unsloth\",  # True o \"unsloth\" para contexto largo\n",
    "    random_state=3407,\n",
    "    use_rslora=False,  # Soporte para Rank Stabilized LoRA\n",
    "    loftq_config=None  # Soporte para LoftQ\n",
    ")\n",
    "\n",
    "# Asegúrate de seleccionar el split 'train' del dataset\n",
    "train_dataset = dataset['train']\n",
    "\n",
    "# Función para tokenizar el dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, max_length=max_seq_length)\n",
    "\n",
    "# Tokenizar el dataset\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Función para agregar la columna 'labels' al dataset tokenizado\n",
    "def add_labels(examples):\n",
    "    examples['labels'] = examples['input_ids']  # Asigna 'labels' igual a 'input_ids'\n",
    "    return examples\n",
    "\n",
    "# Aplica la función para agregar la columna 'labels'\n",
    "train_dataset = train_dataset.map(add_labels, batched=True)\n",
    "\n",
    "# Configuración del Data Collator para secuencias\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "# Configuración del trainer de Unsloth\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,  # Usar el dataset 'train' con 'labels'\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    data_collator=data_collator,  # Usar el collator modificado\n",
    "    dataset_num_proc=2,\n",
    "    packing=False,  # Puede hacer el entrenamiento 5x más rápido para secuencias cortas\n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=32,\n",
    "        gradient_accumulation_steps=2,\n",
    "        warmup_steps=5,\n",
    "        num_train_epochs=2,  # Ajusta el número de épocas aquí\n",
    "        #max_steps=5000,\n",
    "        learning_rate=0.001,\n",
    "        fp16= not is_bfloat16_supported(),\n",
    "        bf16= is_bfloat16_supported(),\n",
    "        logging_steps=1,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=3407,\n",
    "        output_dir=\"outputs\",\n",
    "        report_to=\"none\",  # Usa esto para WandB, TensorBoard, etc.\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nvjyQXyEYG5-",
    "outputId": "efd5bae1-0364-4aff-8ba9-25c05564f458"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 21,084 | Num Epochs = 2\n",
      "O^O/ \\_/ \\    Batch size per device = 32 | Gradient Accumulation steps = 2\n",
      "\\        /    Total batch size = 64 | Total steps = 658\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Unsloth: Please use our fixed gradient_accumulation_steps by updating transformers and Unsloth!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='304' max='658' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [304/658 15:18 < 17:56, 0.33 it/s, Epoch 0.92/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.845300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.789700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.644400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.477500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.288200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.031200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.011700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.889000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.674000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.712400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.490200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.515800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3.595300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3.347200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3.314900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>3.334300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>3.197200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>3.083800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>3.312300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.255200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>3.189400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>3.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>3.276400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>3.142600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>3.169600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>3.131800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>3.035500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>3.117800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>3.097200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.119500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>3.107200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>3.085300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>3.095700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>3.106700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>3.117300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>2.972200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>3.127400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>3.027900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>2.996800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.006400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>2.941700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>3.005200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>2.790400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>2.880800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>3.004400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>2.957800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>2.944000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>2.919300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>2.857900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.851800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>2.798200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>2.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>2.816400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>2.741000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>2.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>2.826000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>2.587500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>2.679900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>2.744800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.770300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>2.783900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>2.636200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>2.752200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>2.648700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>2.740500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>2.742300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>2.782200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>2.672100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>2.794500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.904100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>2.703700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>2.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>2.577200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>2.800600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>2.536400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>2.633900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>2.655900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>2.492200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>2.556700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.711500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>2.639800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>2.620500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>2.606700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>2.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>2.527600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>2.690100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>2.511000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>2.635700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>2.600100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.478200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>2.566800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>2.511200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>2.512300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>2.535400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>2.439300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>2.552800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>2.467800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>2.487300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>2.637700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.396800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>2.393900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>2.499400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>2.370800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>2.633100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>2.437600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>2.455900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>2.445300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>2.382600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>2.550800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.547400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>2.471000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>2.552900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>2.625600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>2.448900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>2.597100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>2.591200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>2.592700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>2.549600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>2.349000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.339500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>2.584300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>2.480200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>2.549000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>2.365300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>2.423900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>2.414100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>2.474700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>2.368200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>2.417200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.423200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>2.195600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>2.354500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>2.430300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>2.503500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>2.691000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>2.210200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>2.487800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>2.278400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>2.330600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.356600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>2.265400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>2.397000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>2.517700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>2.257300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>2.442800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>2.290700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>2.309800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>2.518800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>2.320300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.333800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>2.321900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>2.487600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>2.257600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>2.338500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>2.202700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>2.281400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>2.326500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>2.332300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>2.358200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.445100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>2.368300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>2.205100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>2.382300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>2.320300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>2.215400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>2.289800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>2.306700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>2.353300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>2.460400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.348800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>2.376200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>2.391800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>2.217600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>2.531700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>2.461700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>2.137200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>2.234800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>2.344500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>2.195300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.303000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>2.256100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>2.217900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>2.216400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>2.474500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>2.142700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>2.342500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>2.290600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>2.109300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>2.372300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.303800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>2.273100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>2.296500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>2.240300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>2.292200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>2.193600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>2.243900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>2.396300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>2.454300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>2.123800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.294700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201</td>\n",
       "      <td>2.304700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>2.300400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>2.387300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>2.127500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>2.141600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>2.072000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>2.323600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>2.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209</td>\n",
       "      <td>2.288000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2.216100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211</td>\n",
       "      <td>2.198700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>2.313600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>2.355400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>2.202600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>2.265000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>2.129300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>2.164200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>2.160500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>2.301200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.197500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>2.212600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>2.285600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223</td>\n",
       "      <td>2.336800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>2.332300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>2.213400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>2.271800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227</td>\n",
       "      <td>2.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>2.256000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229</td>\n",
       "      <td>2.222600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.108700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>2.223800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>2.172600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233</td>\n",
       "      <td>2.238500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>2.133500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>2.126600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>2.105700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>2.387800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>2.104800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239</td>\n",
       "      <td>2.192400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.230100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>241</td>\n",
       "      <td>2.183800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>2.119000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>243</td>\n",
       "      <td>2.154300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>2.183400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>2.122400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>2.212700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>2.139900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>2.285100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>2.189600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.240500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>251</td>\n",
       "      <td>2.226500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>2.030200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>2.354100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>2.224500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>2.044500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>2.140300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>2.093800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>2.183700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259</td>\n",
       "      <td>2.174500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.139400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261</td>\n",
       "      <td>2.109700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262</td>\n",
       "      <td>2.119300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263</td>\n",
       "      <td>2.322900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>2.258600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>2.182600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266</td>\n",
       "      <td>2.142300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267</td>\n",
       "      <td>2.185600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>268</td>\n",
       "      <td>2.158300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269</td>\n",
       "      <td>2.067200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.092600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>271</td>\n",
       "      <td>2.067700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272</td>\n",
       "      <td>2.140800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273</td>\n",
       "      <td>2.171200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>274</td>\n",
       "      <td>2.123000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>2.117500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>276</td>\n",
       "      <td>2.205900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277</td>\n",
       "      <td>2.145600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>278</td>\n",
       "      <td>2.161600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>279</td>\n",
       "      <td>2.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.952200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281</td>\n",
       "      <td>2.149300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282</td>\n",
       "      <td>2.183200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>283</td>\n",
       "      <td>1.973700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>2.113700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>2.280100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>2.195600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>287</td>\n",
       "      <td>1.968200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>2.036200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289</td>\n",
       "      <td>2.134800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2.149600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>2.190300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292</td>\n",
       "      <td>2.018400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>2.183400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>2.162200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>2.051900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>2.125300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>1.955700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>2.149800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>2.065400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.193100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>301</td>\n",
       "      <td>2.053800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302</td>\n",
       "      <td>2.240600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('modelo/tokenizer_config.json',\n",
       " 'modelo/special_tokens_map.json',\n",
       " 'modelo/tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"modelo\")\n",
    "tokenizer.save_pretrained(\"modelo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekOmTR1hSNcr"
   },
   "source": [
    "<a name=\"Inference\"></a>\n",
    "### Inference\n",
    "Let's run the model! You can change the instruction and input - leave the output blank!\n",
    "\n",
    "**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**\n",
    "\n",
    "We use `min_p = 0.1` and `temperature = 1.5`. Read this [Tweet](https://x.com/menhguin/status/1826132708508213629) for more information on why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kR3gIAX-SM2q"
   },
   "outputs": [],
   "source": [
    "def format_prompt(instruction, input_text):\n",
    "    return f\"Instruction: {instruction} Input: {input_text} Output:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8tsHVk_ja-Qb"
   },
   "outputs": [],
   "source": [
    "def tokenize_prompt(prompt, tokenizer, max_seq_length):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=max_seq_length)\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WXJ8wcoMbAaI"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def generate_response(prompt, model, tokenizer, max_seq_length=256, max_new_tokens=50):\n",
    "    # Formatear el prompt\n",
    "    formatted_prompt = format_prompt(prompt[\"instruction\"], prompt[\"input\"])\n",
    "\n",
    "    # Tokenizar el prompt\n",
    "    inputs = tokenize_prompt(formatted_prompt, tokenizer, max_seq_length)\n",
    "\n",
    "    # Pasar el prompt al modelo y generar una respuesta\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,  # Número máximo de tokens a generar\n",
    "        do_sample=True,  # Muestra aleatoriamente para más diversidad\n",
    "        temperature=0.7,  # Controla la creatividad de la respuesta\n",
    "        top_p=0.9,  # Controla el filtro de nucleus sampling\n",
    "        eos_token_id=tokenizer.eos_token_id  # ID del token de fin de secuencia\n",
    "    )\n",
    "\n",
    "    # Decodificar la respuesta generada\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Mostrar la respuesta generada después del prompt\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KSg5pnDjbITh",
    "outputId": "959b7ea9-695e-4449-9690-d7d54d37ad93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta del modelo: Instruction: Traduce el siguiente texto a Nahuatl Input: Dame un pedazo de ese chocolate amigo Output: Xinehualti notlatl axoxa notlatl axoxa notlatl axoxa notlatl axoxa notlatl axoxa notlatl axoxa notlatl axoxa notlatl\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "\n",
    "# Preparar el modelo para inferencia\n",
    "model = FastLanguageModel.for_inference(model)\n",
    "\n",
    "def format_prompt(instruction, input_text):\n",
    "    return f\"Instruction: {instruction} Input: {input_text} Output:\"\n",
    "\n",
    "def tokenize_prompt(prompt, tokenizer, max_seq_length):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=max_seq_length)\n",
    "    return inputs\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def generate_response(prompt, model, tokenizer, max_seq_length=256, max_new_tokens=50):\n",
    "    # Determinar el dispositivo\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Formatear el prompt\n",
    "    formatted_prompt = format_prompt(prompt[\"instruction\"], prompt[\"input\"])\n",
    "\n",
    "    # Tokenizar el prompt\n",
    "    inputs = tokenize_prompt(formatted_prompt, tokenizer, max_seq_length)\n",
    "\n",
    "    # Mover los inputs al dispositivo\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Pasar el prompt al modelo y generar una respuesta\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    # Decodificar la respuesta generada\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "# Ejemplo de un prompt\n",
    "prompt_example = {\n",
    "    \"instruction\": \"Traduce el siguiente texto a Nahuatl\",\n",
    "    \"input\": \"Dame un pedazo de ese chocolate amigo\"\n",
    "}\n",
    "\n",
    "# Generar respuesta\n",
    "response = generate_response(prompt_example, model, tokenizer)\n",
    "print(f\"Respuesta del modelo: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "nHTePNMwfVPi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings del prompt: [[-1.78125    -0.1484375   0.6640625  ... -0.5703125   0.48046875\n",
      "  -1.625     ]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_embeddings(prompt, model, tokenizer, max_seq_length=256):\n",
    "    # Determinar el dispositivo\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Formatear y tokenizar el prompt\n",
    "    formatted_prompt = format_prompt(prompt[\"instruction\"], prompt[\"input\"])\n",
    "    inputs = tokenize_prompt(formatted_prompt, tokenizer, max_seq_length)\n",
    "\n",
    "    # Mover los inputs al dispositivo\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Pasar el input por el modelo sin generar texto\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "\n",
    "    # Extraer los embeddings de la última capa oculta\n",
    "    embeddings = outputs.hidden_states[-1]\n",
    "\n",
    "    # Promediar los embeddings a lo largo de la secuencia (opcional)\n",
    "    averaged_embeddings = embeddings.mean(dim=1)\n",
    "\n",
    "    # Convertir a float32 antes de pasarlos a NumPy\n",
    "    return averaged_embeddings.cpu().float().numpy()\n",
    "\n",
    "# Obtener embeddings del ejemplo de prompt\n",
    "embeddings = get_embeddings(prompt_example, model, tokenizer)\n",
    "print(f\"Embeddings del prompt: {embeddings}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto generado: Instruction: Traduce el siguiente texto a Nahuatl Input: Dame un pedazo de ese chocolate amigo Output: Xinehuetzti quin tletl inin tlacualli quipia noca cuicatl amoné Nahuatl  Xinehuetzti quin tletl inin tlacualli qu\n",
      "Embeddings del output: [[-1.3203125  -0.51171875 -0.9609375  ...  0.50390625 -0.48828125\n",
      "  -2.359375  ]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_output_embeddings(prompt, model, tokenizer, max_seq_length=256, max_new_tokens=50):\n",
    "    # Determinar el dispositivo\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Formatear el prompt inicial\n",
    "    formatted_prompt = format_prompt(prompt[\"instruction\"], prompt[\"input\"])\n",
    "    inputs = tokenize_prompt(formatted_prompt, tokenizer, max_seq_length)\n",
    "\n",
    "    # Mover los inputs al dispositivo\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Generar el output con el modelo\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    # Decodificar el output generado para obtener el texto\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Tokenizar el texto generado para obtener los embeddings\n",
    "    output_inputs = tokenizer(generated_text, return_tensors=\"pt\", truncation=True, max_length=max_seq_length)\n",
    "\n",
    "    # Mover el output tokenizado al dispositivo\n",
    "    output_inputs = {k: v.to(device) for k, v in output_inputs.items()}\n",
    "\n",
    "    # Pasar el output tokenizado por el modelo para obtener los embeddings\n",
    "    with torch.no_grad():\n",
    "        output_embeddings = model(**output_inputs, output_hidden_states=True).hidden_states[-1]\n",
    "\n",
    "    # Promediar los embeddings a lo largo de la secuencia (opcional)\n",
    "    averaged_output_embeddings = output_embeddings.mean(dim=1)\n",
    "\n",
    "    # Convertir a float32 antes de pasarlos a NumPy\n",
    "    return averaged_output_embeddings.cpu().float().numpy(), generated_text\n",
    "\n",
    "# Obtener embeddings del output generado\n",
    "output_embeddings, generated_text = get_output_embeddings(prompt_example, model, tokenizer)\n",
    "\n",
    "print(f\"Texto generado: {generated_text}\")\n",
    "print(f\"Embeddings del output: {output_embeddings}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed input 1: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Y así cuando hizo su ofrenda de fuego se sienta delante de los demás y una persona se queda junto a él\" Output: \"Ihuan ihcuac ye otlaneci in tlatoli oncan motlalito in occequih tlacatl ica quipiaya ipan ihuan\"\n",
      "Processed input 2: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Si es jade si es oro acaso no tendrá que ir allá\" Output: \"Tlen cuauhxochimeh tlen cuauhquihtozme acan ye tlapatihui\"\n",
      "Processed input 3: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Y cuando el Sol estuvo solo en el cielo enseguida comenzó a amarillear y fue oscureciendo poco a poco hasta que el Sol desapareció cuando frente a él fue a colocarse la Luna alcanzando a cubrir el disco del Sol y así lentamente desapareció el Sol\" Output: \"Auh in ihcuac in tonatiuh zan ye huitze quixohuac niman ye opeuh in ye huitze huel onpa ye huitze yn ihcuac in tonatiuh ye\n",
      "Processed input 4: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Allá acudieron asimismo los señores del cabildo de la ciudad y los oidores de la Real Audiencia quienes pusieron enmedio a un hombre que llevaba sobre un cojín la corona real y todos iban avanzando al mismo tiempo\" Output: \"Auh ynic niman yehuantin yn cabildo yhuan audiencia yehuatzin yn tlahtoque yn tlacpac tlahtohuani niman yehuatzin omoteneu\n",
      "Processed input 5: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Usos\" Output: \"Inon\"\n",
      "Processed input 6: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Los mexitin adoraban exclusivamente al gran Diablo a fin de que éste se apiadara de ellos los ayudara y los salvara y no permitiera que los mataran y destruyeran a todos sino que los llevara a otro lugar para que en otro sitio bueno y apropiado les diera tierras donde se ocuparían tan sólo en servirlo\" Output: \"In mexitin quimandarohua ica yehuatzin huey cihuatzintli yn quenin quimati yn quenin quimochihuilli auh quenin quinmocahuilli yn\n",
      "Processed input 7: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"También vino de España para ser aquí juez de los obrajeros otro caballero llamado don Francisco de Cardona comendador de Montesa que igualmente vestía el hábito de su encomienda con una cruz roja\" Output: \"Auh no yhuan España oquimocacacopa ynic nican quimohuiquillizque obrajeros occe yehuatl quimopalehui yn don Francisco de Cardona comend\n",
      "Processed input 8: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Este hombre es rico\" Output: \"Inin tlacatl quipia rico\"\n",
      "Processed input 9: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"En este año se enseñoreó Tziuhtécatl como tlatohuani de Colhuacan\" Output: \"Yn ipan in xihuitl y motlahtocatlalli yn itoca Tziuhtecatl tlahtohuani mochiuh yn Culhuacan\"\n",
      "Processed input 10: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Se vende en Cuetzalan\" Output: \"Mochiua Kuesalan\"\n",
      "Processed input 11: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Solo hay una clase\" Output: \"Zan nochtlahcan\"\n",
      "Processed input 12: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"No te enriquezcas con dinero mal habido\" Output: \"Ma tictoneltilia ximohuaya ixtlahuapa\"\n",
      "Processed input 13: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Sirve para comerse se tuesta en el comal\" Output: \"Kualtia se kikua itech komatl para se kikua ixua komalt\"\n",
      "Processed input 14: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Hay por Kalikan Texayakatitan en el monte en el cafetal y no lo cortan porque su fruto se come\" Output: \"Onkak Kalikan Texayakatitan ne kajfentaj uan amo monamaka kipixka pampa in itakka se kikua\"\n",
      "Processed input 15: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"6 Tochtli 1602\" Output: \"VI Tochtli xihuitl 1602\"\n",
      "Processed input 16: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Se cortan en trozos medianos los hongos muy limpiecitos al epazote se le cortan las hojitas y todo esto se pone sobre un comal a fuego bajo con sal al gusto y las venas o los chiles Se tapan con una cazuelita hasta que estén cocidos Comúnmente se comen en tacos\" Output: \"Mochiua in tepitzin in xonacatl zan cuahcualtin in quauhtli in ye mochiua in xonacatl motlalia in tepoztli in ixiuhcahu\n",
      "Processed input 17: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"En este año vinieron a Mexico Tenochtitlan los guardianes de las trojes de Amaquemecan para hablar con el tlacateuctli Itzcohuatzin cuando éste no era aún tlatohuani sino sólo tlatocapilli en Mexico el tlatohuani era Huitzilíhuitl Segundo y su teuctlato era el tlacochcálcatl Cuatlecóhuatl\" Output: \"Auh no yquac nican Mexico Tenochtitlan huallaque yn Amaquecomecan tlacateuhctli yn quinotzintiaque yn Itzcohuatzin tlacateuhctli\n",
      "Processed input 18: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Mochiua kampa se kitoka kemej yon milaj\" Output: \"Mochiua kampa se kitoka kemej yon milaj\"\n",
      "Processed input 19: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Por ser todavía muy niño a Cohuazacatzin no lo ataviaron con las insignias señoriales pero a la señora Tlacocihuatzin que era la madre de Cohuazacatzin sí la ataviaron señorialmente le pusieron el tocado señorial y el xiuhhuitzolli y le dieron las demás insignias distintivas del señorío\" Output: \"In Cohuazacatzin amo yuh ye tlapixqui yhuan ayac quimixhuihuitiaya yn inhuellamatzin Tlacocihuatzin ca yehuatl yeh\n",
      "Processed input 20: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Después de que Cuacuauhpitzáhuac se asentó como tlatoani los mexicas vencieron a los chimalhuacas\" Output: \"Auh yn motlahtocatlalli yn Quaquauhtzin ynic tlatoani mexica yn quinpeuhque yn chimalhuaca\"\n",
      "Processed input 21: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Y esto sabe y es la verdad para el juramento que hizo en lo qual se afirmó y ratificó y dixo es de hedad de ochenta años y rogue al escrivano lo firmase por mí porque no se escrevir Don Gaspar de Mendoza Pedro Daniel Ante mí Francisco Millan escrivano\" Output: \"Auh in yehuatl in tlamantli ynic otlanequiliz in testigo ynic oquito onicac juramento auh ynic omonamicti ynic oquito oquicac y\n",
      "Processed input 22: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"El capitán español salió precipitadamente de México para combatir en Veracruz al recién llegado\" Output: \"Cuitlapanecuhtli yca quimocuitlahui Mexico quinmocuepaztia yn ipan Veracruz ynin quicauh\"\n",
      "Processed input 23: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"la yucachakaykuoujkamoj y el guacamote blanco istakkuoujkamoj\" Output: \"Iyakachakaykuoujkamoj uan istakkuoujkamoj\"\n",
      "Processed input 24: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"La sirvienta puso cuatro cubiertos sobre la mesa\" Output: \"Ihuan quicuecholtiqueh in quicuacalhuan quimomaquili in nacatl\"\n",
      "Processed input 25: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"En 12 pedernal se fueron los mexicas a Tecpayocan\" Output: \"Ipan matlactli tonalli oncan hualquizque mexica nican Tecpayocan\"\n",
      "Processed input 26: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Los sabedores de discursos es de ellos obligación se ocupan día y noche de poner el copal de su ofrecimiento de las espinas para sangrarse\" Output: \"In tlatquihuaque ye quin otechmopahualtiaque in ixquich in quihualmopahualtiaque in copal in tlaquahuitl in motlalia\"\n",
      "Processed input 27: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Si vendiese la casa ya no tendría ninguna propiedad\" Output: \"Tla quitlacozqui ipan calic aca amo quipiaz in cali\"\n",
      "Processed input 28: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Habiendo salido los españoles se detuvieron en Acueco prosiguieron adelante y se detuvieron en Teocalhueyacan partieron con rumbo a Zoltépec partieron y se detuvieron en Tepotzotlan partieron y se detuvieron en Citlaltépec se pusieron en marcha y se detuvieron en Temazcalapan donde los recibieron bien y les dieron guajolotes huevos y maíz y donde tomaron algún respiro\" Output: \"Auh ynic acico oncan Acueco ynic oncan quihualmihque ynic oncan quihualhuicaque Teocalhuacan ynic oncan quihualmihque ynic on\n",
      "Processed input 29: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Es quelite kilit\" Output: \"In kilit\"\n",
      "Processed input 30: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Venas de chile\" Output: \"In tletl\"\n",
      "Processed input 31: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Han pasado 77 años desde que en el año 1 Técpatl 1532 se instaló como cuauhtlato don Pablo Xochiquentzin entonces a los tres años regresaron a México los que habían ido a Teocolhuacan\" Output: \"Auh yhuan ye nauhxihuitl yn ipan ce Tecpatl xihuitl 1532 años yn oquauhtlahtocatlallic yn don Pablo Xochiquentzin auh ypan\n",
      "Processed input 32: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Se da en el monte y en el cafetal\" Output: \"Mochiua kampa tepetl uan kampa kajfentaj\"\n",
      "Processed input 33: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"por medio del acueducto es su descenso\" Output: \"itlamamauhqui\"\n",
      "Processed input 34: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"77\tHijo mío date ánimo Quizás aquí poco tiempo un día estás esperando su piedra su palo su enfermedad y pestilencia del Señor Nuestro En su agua en su cerro andas derramando el llanto las lágrimas un día dos días No con tranquilidad no con alegría vienes a levantarte vienes a despertar no con tranquilidad no apaciblemente haces el sueño el reposo con el favor de alguien al lado de alguien tu cabecera sólo está repleta de tu calzado estropeado de tu bordón y de tu huacal tu tortilla doblada tu coa tu utensilio para cargar con lo cual te elevó te honró el Señor Nuestro Eres águila eres ocelote es tu dádiva es tu merecimiento Eres animoso eres el cantor de la gente Con el adobe el amasijo la angarilla el bordón la coa el utensilio para cargar ayudas al agua al cerro a la estera al sitial con ello educas con ello fortaleces al Señor Nuestro a la tierra a la gente\" Input: 77 Inic nicmati in tihuallamauh inic timonamiqui In ahquihui in\n",
      "Processed input 35: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"El domingo 18 de julio de 1593 se trasladaron a San Juan de la Penitencia las señoras monjas hijas de Santa Clara vinieron sólo cinco y llegaron por la tarde a las 4\" Output: \"Domingo a 18 de julio de 1593 años yquac motlallique yn San Juan de la Penitencia yteopantzinco yn inmonjastin Santa Clara monjastin yn o\n",
      "Processed input 36: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"En el dicho Tizayocan Tlaquilxochtzin señora de Tzompanco dio a luz un hijo varón al que llamaron Huehue Huitzilíhuitl cuyo padre era un mexica chichimeca\" Output: \"Auh yn Tizayocan Tlaquilxochtzin cihuapilli Tzompanco yn quincauhtiuh yn itoca Huehue Huitzilihuitl chane yn iuhqui mex\n",
      "Processed input 37: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"En la ciudad de Mexico Tenochtitlan en jueves veynte y cinco dias del mes de setiembre de mill y quinientos y ochenta y seys años ante Miguel de los Angeles alcaldes hordinarios por su magestad en esta ciudad de Mexico en audiencia publica\" Output: \"Yn nican ciudad de Mexico Tenochtitlan juebes a veynte y cinco dias del mes de setiembre de mil e quinientos y ochenta y seys años yn audiencia audiencia publica Miguel de los Angeles\n",
      "Processed input 38: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Este quelite florea en agosto cuando ya está maduro Lo hay sólo por temporadas no siempre\" Output: \"In xokot in se kemej ajkuajko ipan agosto Komo semitik pané amo semi mochiua\"\n",
      "Processed input 39: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Partieron para establecerse en Apazco donde al segundo año erigieron un altar de tierra murió Apanteuctli y en su lugar pusieron a Cítlal allá se quedaron tres años\" Output: \"Auh ynic ompa hualmocuepato yn Apazco ynic otlalhuico oncan ynic quimotlalli yn yn tlalli yn omoteneuh ynic omotlacahual\n",
      "Processed input 40: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"En este año salieron de Teocolhuacan que está cerca de Aztlan los antiguos chichimecas totolimpanecas que ahora se llaman amaquemecas cuando llevaban allá 1160 años se movieron para venir caminando hacia acá\" Output: \"Nican ypan in yn oncan Teocolhuacan yn oncan Aztlan yn huehuetque chichimeca totollimpaneca yn amauameque auh yn ihcuac ye onpohualx\n",
      "Processed input 41: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"8 Técpatl 1500\" Output: \"VIII Tecpatl xihuitl 1500 años\"\n",
      "Processed input 42: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"E que asi mesmo sabe que ninguna persona las a tenido ny a pretendido tener abcion a ellas porque las tierras fueron o hobieran sydo de otra persona este testigo lo supiera Le fue dicho al testigo Cómo sabes Acaso alguien allí labraba para la mujer del Tolteca Dijo el testigo Nos confunde pues apenas hace dos años allá cayó y no sabemos como es que se hace de surcos pues desde luego asi se que la tierra pertenece a Alixeliuhqui Y questa es la berdad para el juramento que thiene hecho\" Output: \"Ynic tlatzilini ca ayac oquincauilli yn tlacatl ca ayac oquimotlatlalili yn tlalli ca ayac oquimomotlalili yn iuhqui tlacpac\n",
      "Processed input 43: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"El 24 de febrero de 1613 primer domingo de cuaresma y fiesta de San Matías por la tarde salió de México hacia la ciudad de los Ángeles Cuetlaxcohuapan el señor licenciado don Pedro de Otálora presidente de la Audiencia Real de México para ser allá ordenado como religioso clérigo y asimismo para ser ordenado con la epístola y el evangelio y para decir la misa y en dos días de esta cuaresma lo ordenó el obispo don Alonso de la Mota y Escobar el Santo Padre había mandado que se hiciera en tres días mas a pesar de este mandamiento en la domínica de Pasión se terminó la ordenación para que pudiera decir la misa\" Output: \"Auh yn ipan axcan yhuan yancuic domingo de cuaresma yn ipan cemilhuitl mani metztli febrero de 1613 años yhcuac yn oquic\n",
      "Processed input 44: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Dejó cinco hijos al primero llamado Acolnahuácatl Tzacuálcatl lo puso a gobernar en Tlacopan al segundo llamado Cuacuauhpitzáhuac lo puso a gobernar en Tlatelolco al tercero llamado Epcohuatzin lo puso a gobernar en Atlacuihuayan al cuarto llamado Maxtlatzin lo puso a gobernar en Coyohuacan a la quinta llamada Ayauhcíhuatl la pidió por esposa Huitzilíhuitl tlatohuani de Tenochtitlan y fue la madre del tlatocapilli Chimalpopoca\" Output: \"Auh yn omoteneuh yn icce ytoca Acolnauaca Tzaqualcatl yehuatl yntlahtocauh mochiuh yn ipan Tlacopan yn icome ytoca Quaqu\n",
      "Processed input 45: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"4 Técpatl 1340\" Output: \"IV Tecpatl xihuitl 1340\"\n",
      "Processed input 46: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Ya no pueden comer acaso los procuran pero ellos tienen el corazón afligido no más están pensando en su muerte\" Output: \"Amo cualli tlatlataca inic quicua ca zan oquimolhuilitihui amo miec in momimiquiliz\"\n",
      "Processed input 47: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Ya van ya están preparados Embriágate embriágate obra el Dios de la Dualidad el inventor de hombres el Espejo que hace aparecer las cosas\" Output: \"Auh zan ye tla niman ye tiquizazque Oticxihuan Oticxihuan zan ye tiquixixitinia in Dios yehuatzin in quin ixcochilia in\n",
      "Processed input 48: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Tolteca artista discípulo abundante múltiple inquieto El verdadero artista capaz se adiestra es hábil dialoga con su corazón encuentra las cosas con su mente\" Output: \"Tolteca teyacanqui tlacahuan chichinahuan in tlahcuiloltin cualli in tlachialtic in icnotlacatl tlatzintla in quimocuepilia\n",
      "Processed input 49: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Ésta le respondió Escúchame bien dime a cuántos teules soldados mataste\" Output: \"Quimilhui Acah in oticchihua Cac tinechmomaquixtia in intlahtul itztic in teotl\"\n",
      "Processed input 50: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Pero otros antiguos tlazopipiltin dicen y consignan pues así lo dejaron pintado en sus papeles que cuando Atonaltzin se disponía a partir hacia Cuauhnáhuac y hacia Michhuacan aún no habían merecido tierras ni habían puesto todas sus mojoneras ambos tlatoque mencionados a saber Atonaltzin y Cuahuitzatzin\" Output: \"Auh ynin occequintin huehuetque yn tlazopipiltin quitoque quimotlaltique yn iuh quimachiyotia yn intlahtul yn quenin quitocay\n",
      "Processed input 51: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Yo he visto a su hermano\" Output: \"Nehua ye oniquitac noconetzin\"\n",
      "Processed input 52: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Hay dos clases chalahuite que se da en el monte y el que se da por acá\" Output: \"Onkak ome taman chalahuitej yejueyi uan yon mochiua nikan\"\n",
      "Processed input 53: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"nuestros\" Output: \"totehuacan\"\n",
      "Processed input 54: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Preparación\" Output: \"Tlatzopeloh\"\n",
      "Processed input 55: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Y sus ataderos del cabello eran cordones de hilos de muchos colores rojo vivo amarillo azul negro Con estos cordones están entretejidas plumas blancas\" Output: \"Ihuan icacatlapalcan in cuetzamachmictiuh inic quipiltotonca in icacatlapalcan yehuan in ye itzticacacuahuitl in icac\n",
      "Processed input 56: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Una bebida muy tradicional de la región es el tepache que se prepara de la siguiente manera     Las tres pizcas de anís y las rajitas de canela se echan dentro de una bolsita de manta y se cierra bien esto se pone dentro de un recipiente con alrededor de cinco litros de agua que debe hervir durante varios minutos después se muele el chile ancho se cuela en el agua que estará hirviendo y se agrega el piloncillo A esto se le pone unos ocho litros de pulque y se deja enfriar para poderse beber\" Output: \"Ce tlaolli tecocoxca in inemiliztzin tlalpan mocua in tepach ixquich inic mochihuaz inon in tlacuilolli in chilaxca ahmo cualli\n",
      "Processed input 57: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Le llaman así porque sus hojas son espinosas uitsyo\" Output: \"In iujki kitokaytiaj por in ixuiyo\"\n",
      "Processed input 58: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Allá donde no hay muerte\" Output: \"Nian ompa amo miqui\"\n",
      "Processed input 59: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"En el año 3 Ácatl 1391 se enseñoreó Huitzilihuitzin en Tenochtitlan\" Output: \"III Acatl xiuitl yquac motlahtocatlalli Uitziliuitzin Tenochtitlan\"\n",
      "Processed input 60: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Sí señor Pienso rentar una pieza Si gusta pase a verla\" Output: \"Tehuatzin Aquinon nimitzmaca se tepoztlacatl Quimixmati tlacualo\"\n",
      "Processed input 61: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"En este año llovió mucho y se dio bien el maíz\" Output: \"Ipan inin xiuhpan xochiyoua ihuan mochiuaya maiz\"\n",
      "Processed input 62: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Bueno Quién habla\" Output: \"Huelic Ac quito\"\n",
      "Processed input 63: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"83\tY si causaste aflicción no junto a la gente al lado de las personas vivirás porque luego serás perseguido serás echado así harás conejos harás venados harás salvajes a tu mujer a tus hijos En ningún lugar será tu casa en ninguna parte el interior de tu hogar verás de allá saldrá la miseria lo que aflige lo que angustia a la gente en ningún lugar tu nopal en parte alguna tu miel verás Si así haces si así vives sólo de tu voluntad te mostrarás a lo que enferma a la gente a lo que la aflige a lo que la angustia sólo de tu voluntad te meterás entre andrajos entre bragueros estropeados sólo de tu voluntad tomarás lo no bueno lo no recto la perversidad lo que deshonra lo que deprava la desobediencia la terquedad\" Output: \"83\tAuh intla otiquintlaquixtili intla otiquixtili in tlalticpac ca niman oncan tzacuticac ca zan nican tiquinmaniliz tiquinpop\n",
      "Processed input 64: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Pues no quieren que envíe clérigos a asentarse por todo el arzobispado y por eso le hacen contradicción los frailes quién sabe cómo irá a acabar este pleito sólo Dios nuestro señor puede saberlo pues todavía está en curso el asunto\" Output: \"Auh ca amo quinequia ynic clérigos yehuatzin quimotlacoltilizque yn ipan in arçobispado yhuan ynic niman quinequia ynic motlanahu\n",
      "Processed input 65: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"\tPues cuando daba órdenes Motecuhzoma de ir en exploración real a determinada región los traficantes y los comerciantes encubiertos si allá se hacía cerco sobre ellos si iban a morir allá ya no podían obedecer el mandato de Motecuhzoma\" Output: \"\tAuh in ic quimitalhuia in Motecuhzoma in ic quin ihuianpanaliz in ye moxtli in intlahtoltiuh in tlahtocayotl in tlahtoc\n",
      "Processed input 66: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"El caudillo de éstos era Huitzilopochtli cuidador y servidor del gran diablo Tetzauhtéotl el cual a menudo se aparecía a Huitzilopochtli y hablaba con él y cuando después Tetzauhtéotl lo dejó en su lugar fue cuando tomó el nombre de HuitzilopochtlI\" Output: \"In Huitzilopochtli in tlatohuani yehuatl quipia yuhquin tlacatl in iteco Tetzauhteotl quinixmatiaya in iuhqui Huitz\n",
      "Processed input 67: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Es un encanto verlas jugar alegremente alrededor de los arbustos y flores\" Output: \"In piltontli xihuiti quichichihua in tetepehuan xochimamanalpan\"\n",
      "Processed input 68: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"De esta manera viven en su orden estos religiosos y sepan todos que así los verán si fuere la voluntad de Dios nuestro señor que vengan acá y mucho nos alegraremos por ello en San Antón de México en la Nueva España mas si no fuere tal la voluntad de Dios nuestro señor pues no vendrán\" Output: \"Ihcuac yehuatl in quimonequia in teopixque in quimati nohuian quincahuazque in tlahtolli inic quimocaquilti yn totecui\n",
      "Processed input 69: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"En seguida el año 7 pedernal llegaron los mexicas a Amalinalpan que pertenece al señorío de Azcapotzalco\" Output: \"Nican pehua yn xiuitl quinpeuhque mexica Amalinalpan catca yn itlahtocayopan Azcapotzalco\"\n",
      "Processed input 70: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Después de que en este dicho año de 1 Técpatl 1272 los nonohualcas teotlixcas tlacochcalcas tecpantlacas salieron de Huehuetlapallan Nonohualco comenzaron a venir caminando hacia acá atravesando cactales magueyales cañaverales herbazales zacatales llanos cerros y barrancas\" Output: \"Ipan in omoteneuh xihuitl Ce Tecpatl 1272 años in yn omoteneuh ypan ce Tecpatl xihuitl 1pohualxiuitl in oncan Huehuet\n",
      "Processed input 71: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"El domingo 10 de octubre de 1610 el señor don Antonio Valeriano el Joven se casó con la señora doña Bárbara que era su pariente pues ambos eran bisnietos del señor don Diego de Alvarado Huanitzin quien fue tlatohuani de Tenochtitlan\" Output: \"Domingo a X de octubre de 1610 años yquac miquico yn tlahtohuani don Antonio Valeriano el Joven ynin cihuapilli doña Bárbara ynin cihu\n",
      "Processed input 72: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"4 Acatl 1431\" Output: \"IIII Acatl xihuitl 1431\"\n",
      "Processed input 73: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"En este año murió nuestro querido padre fray Alonso de Molina religioso de San Francisco que era nuestro predicador\" Output: \"Ypan in ypan in omomiquillico yn totatzin fray Alonso de Molina San Francisco teopixqui catca\"\n",
      "Processed input 74: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"3\tdientes de ajo\" Output: \"Yei axoxtlantli\"\n",
      "Processed input 75: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"las vuestras\" Output: \"in nopa\"\n",
      "Processed input 76: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Los chichimecas totolimpanecas estuvieron mucho tiempo en Aztlan Teocolhuacan pues llevaban allí 1160 años cuando se movieron y partieron para venir caminando hacia acá\" Output: \"In chichimeca totollimpaneca oncan cenpohualloncaxtolli ipan matlactli onpohualxihuitl onpohualxihuitl ipan matlactlome\n",
      "Processed input 77: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Muchas gracias Dónde podría comprar unas estampillas\" Output: \"Cualica tiquitoa Canin niquinamaca estampitla\"\n",
      "Processed input 78: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Testigo Francisco de Luna casado habitante del tlaxilacali de San Martin Atexcapan hizo juramento ante dios nuestro señor y la Virgen Sancta María y por la señal de la Santa Cruz Le fue impuesta culpa para que rectamente diga lo que sea preguntado si dice verdad dios lo premiará y sino sera castigado en el infierno el así dijo que dirá verdad\" Output: \"Testigo Francisco de Luna tlaxilacaltlahtocatca Sant Martin Atxcan oquichiuh juramento yn iuh quimopalehuililico yn totecuyo dios yn ilhuicatl yn\n",
      "Processed input 79: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"También en todas las iglesias de los monasterios en que hay frailes religiosos se hicieron plegarias por el dicho señor arzobispo asimismo se hicieron plegarias en todas las iglesias de los monasterios de monjas y diariamente durante una semana estuvo expuesto el Santísimo Sacramento a fin de que el arzobispo no muriera sino que Dios nuestro señor le diera salud\" Output: \"No yhuan yn izquican monasterios teopan quimonamiquillique yhuan yn izquican monjas teopan monaxin teopixque yn iuh quimonamiquillique y\n",
      "Processed input 80: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"En este año los mexicas se trasladaron a Tizayocan donde se quedaron un año\" Output: \"Ypan in ynic oncan motlallico Tizacocan ynic ome xihuitl oncan motlallico\"\n",
      "Processed input 81: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Sal al gusto\" Output: \"Zan nimitztlacuihui\"\n",
      "Processed input 82: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Se fue éste a buscar a susmujeres les dijo\" Output: \"Yehuatl oquimocuitlahuia in inamic niman oquimilhui\"\n",
      "Processed input 83: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Y las casas fueron edificadas por el padre y por la madre vieja y sobre el pleyto que trae agora Pedro Mazaquen en esto no tiene que dezir ni tanpoco Ynes Tiacapan solo las quiere husurpar y las desea y son de difuntos y lo que la Maria Joco mandó se vendan las casas lo declaró en nuestra presencia porque el tiempo que estuvo enferma la servimos y esto responde este testigo Pedro Hernandez Puso su firma\" Output: \"Auh yn calli yc quihualmocuitia yn tatzin catca yhuan yn matzintli catca auh yn ipan yxpan ynic monamaca Pedro Mazaquen auh\n",
      "Processed input 84: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Testigo Miguel Uitztecpancatl habitante de San Sebastian Zacatla casado su edad es de setenta y cinco años Juró y fue penado para que no diga mentira\" Output: \"Testigo Miguel Uitztecpancatl chane San Sebastian Zacatla onca cenpohualli matlacpohualxihuitl yxiuhtzin ye quipia caxtolpohualxih\n",
      "Processed input 85: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"1\tkilo de hongos yemitas\" Output: \"Ce kilo ehecatl ahnozo ehuatl\"\n",
      "Processed input 86: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"En la cocina ayuda a lavar los trastes\" Output: \"In cocina quitlaxililia in trastes\"\n",
      "Processed input 87: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"En este año abandonaron su ciudad los tlalhuacpanecas para ir a establecerse en Cuauhximalpan allá estuvieron dos años pero luego nuevamente se fueron a Atzacualoyan enmedio del bosque\" Output: \"Ipan inin xihuitl oncan yn motlallico tlallanca yn tlalhuacpaneca ynic oncan yn oncan huecauh yn oncan quincauhtique yn Cuauhximalpan\n",
      "Processed input 88: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Se da en el cafetal y en la milpa\" Output: \"Mochiua kajfentaj uan milaj\"\n",
      "Processed input 89: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"No se vende\" Output: \"Amo kualtia\"\n",
      "Processed input 90: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Komo amo se kitoka pos amo mochiua\" Output: \"Tona amo se kitoka pos amo mochiua\"\n",
      "Processed input 91: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"vendais\" Output: \"tictlaxtlahuazqueh\"\n",
      "Processed input 92: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Les decía Señores ya basta Qué estáis haciendo Pobre gente acaso traen escudos y macanas Están desarmados\" Output: \"Quimilhuih Tlatzitzilque zan ye oc tiquihtohua Tlacameh ahmo tiquihtohua In tlacameh zan cuacualacalhuan t\n",
      "Processed input 93: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Al oírlo los mexicas se echaron a llorar pero el diablo Huitzilopochtli les dijo nuevamente No os aflijáis vayamos a cantar\" Output: \"Auh yn oquicacque yn mexica ynic oncan quimilhuique yn Huitzilopochtli ynic oncan tlatzintlaquimilhuiaque Auh yxqu\n",
      "Processed input 94: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Lo tiraron al agua y los animales de la laguna le comieron el rostro lo mataron en la taberna de Morejón en Temaztitlan por alguna razón sus propios parientes lo mataron degollándolo con una espada y luego huyeron\" Output: \"Oquimotlalilique on atl ihuan in cuauhtla omomiquilique in oncan in itech Morejon Temaztitlan in oncan oquimictique inic nozo quimictia\n",
      "Processed input 95: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"la suya\" Output: \"in icel\"\n",
      "Processed input 96: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Y encima de las iglesias de los monasterios se encendieron muchas candelas de sebo como todos lo vieron\" Output: \"Auh yhuan yn teopantli yn teopixque ynic cenca mocuepque yn ipan candelas mochiuh ynic nohuian ye onca\"\n",
      "Processed input 97: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"2\tdientes de ajo\" Output: \"Ome axoxtlantli\"\n",
      "Processed input 98: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"El fruto se come cuando ya está maduro se corta y así ya se come\" Output: \"Se kikua in ikuoujyo ijuak peua se kitexka uan se kikua\"\n",
      "Processed input 99: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"\tY fue entonces cuando discutieron al haberse reunido en junta dijeron\" Output: \"\tAuh in iquac oncan niman iquac omoyectiaya in ic ualmotlahtoaya\"\n",
      "Processed input 100: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Este año da inicio la llamada Guerra Cristera\" Output: \"Inin xiuhpan inin oquitlahtocatlalli inin oquicuac itoca Cristera\"\n",
      "Processed input 101: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Cuando uno lo limpia ya está floreando\" Output: \"Ijcuac se kipajtia se kipoyeli\"\n",
      "Processed input 102: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Yten declaro que tengo un retablo grande de la transfiguracion mando se lleve al monasterio de Santiago para que esté allá donde quisieren los padres\" Output: \"Ynic tiquitlanico ynic oncan tlauhtlamantli yn motamachiuh in tlaixpanahuian yn oncan quimocahuizque yn nican monasterio Sanctiago ynic\n",
      "Processed input 103: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Se lava la carne y se pone a hervir hasta que quede bien cocida Los hongos limpiecitos se ponen en una cazuela y se tapan para que se cuezan al vapor pero si se desea a esto se le puede agregar una cucharada de manteca Se ponen a hervir los tomates los chiles el ajo y la cebolla en una olla con una taza y media de agua cuando ya estén suaves se muelen y se agregan a los hongos junto con la carne y el caldo Se deja hervir de 20 a 30 minutos\" Output: \"Mozozoyonictzitzihua ihuan moteci ica huicac momana in tleco In cuacuahhuentzitzin moteci ica cuacualaca inic cuahuitl\n",
      "Processed input 104: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"La casa está bonita por fuera pero por dentro no\" Output: \"In cali cualli cuahuitl itechpa pero\"\n",
      "Processed input 105: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Luego nuestro padre se arrodilló frente al altar mayor y lloraba diciendo Ya no os preocupéis mexicas porque ya no veréis la piedra y el palo ya me arrepiento después fue junto a la columna donde exhibía y afrentaba a la gente abrazó la columna y comenzó a azotarse y le dijo al fiscal Azótame\" Output: \"Niman in totahtzin omotlalico ye ipan tlahtoani itech motlapachotia quimilhuiya Mopialia amonca ahmo titohuica mexica amon\n",
      "Processed input 106: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"En vano hemos llegado hemos brotado en la tierra\" Output: \"Zan tica in in otia in tonalli\"\n",
      "Processed input 107: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"fueras estuviera\" Output: \"tla aman\"\n",
      "Processed input 108: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"También en este año Tizocicatzin impuso por primera vez a los chalcas la tarea de traer árboles a rastras desde Xochiquiyauhco a un lado del Popocatépetl vinieron arrastrando grandes árboles\" Output: \"Auh no yquac yn ipan in xihuitl yn oquicuic yn chalca ynic tlayahualloliztli ynic motlallica yn Popocatepetl yn oncan yn X\n",
      "Processed input 109: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"El que es blanco tiene su ombligo negro y el ejote es chiquito y el frijol es blanco\" Output: \"In kemej kuoujxoxoujyo iuan in xoxoujyotsin uan in kuoujxoxoujyo inon kuoujyotsin iuan in kuoujxox\n",
      "Processed input 110: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \" No vayais en vano\" Output: \"Xcaquican para ocsejpa nenquichihuasquej \"\n",
      "Processed input 111: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Después de salir durante 13 años anduvieron caminando por entre magueyales y cactales\" Output: \"Yhuan ye onpohuallonchicuehualtica ye noxihuitl yn ompa huallaque quauhtzitzintin ihuan xochimeh\"\n",
      "Processed input 112: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"El dicho Totoltécatl Tzompachtli Tlailotlacteuctli murió en cuanto llegó a la ribera en el dicho año de 6 Tochtli 1238 gobernó durante 20 años en Tizatépec y durante 10 años en Cuitlatetelco de modo que fue tlatohuani de los eztlapictin tenancas durante 30 años\" Output: \"Auh yn omoteneuh Totoltecatl Tzonpachtli Tlayllotlacteuhctli yn oncan mochiuh yn acico ynic oncan caxtolxihuitl yn ip\n",
      "Processed input 113: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Luego empezaron a repartir premios a los que habían pasado el año Y me dieron un diploma donde estaba escrito  YO PORFIRIO DÍAZ PRESIDENTE DE MÉXICO EN NOMBRE DE LA PATRIA REPARTO ESTAS MEDALLAS PORQUE SON APLICADOS LOS NIÑOS QUE NUNCA OLVIDEN QUE GUARDEN EN SU MEMORIA LO QUE HAN APRENDIDO BIEN\" Output: \"Niman ye icuac on oquimomachitiaya tlahuicxitilli in tiquintequiliaya in oquimotlalilique in oquimomaquixtilique diploma in quimot\n",
      "Processed input 114: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Se da donde lo siembran\" Output: \"Mochiua kampa kitoka\"\n",
      "Processed input 115: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Mucho reclaman tu rostro tu corazón tu cuerpo en recompensa porque así por mí te privaste de algo así me criaste Junto al fogón en el hogar sobre mí cabeceabas preocupada si me habías lastimado el labio o si me arrullabas porque por mí temiste que algo imprevisto pudiera ocurrir no con tranquilidad hiciste el sueño el descanso bien por mí velaste y con tu mano recogías mi orina mi excremento no con tranquilidad no apaciblemente no sin dificultades se hacía enjundiosa venía a derramarse tu lechecita que en mi boca echaste me escurriste\" Output: \"Moztla tictlachicahuazque in moyolchicahualtzin in moyotl in moconeu in nican titechmacac In tihuallehuacan tihualmop\n",
      "Processed input 116: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Cuando los antiguos chichimecas llamados aztecas llevaban 1014 años de estar en aquella isla en la nombrada gran ciudad de Aztlan y según dicen y dejaron pintado los antiguos en el año 1 Técpatl de su cuenta que corresponde al año de Dios nuestro señor que arriba aparece es decir a 1064 cuando habían transcurrido 1064 años desde el nacimiento del Hijo del verdadero Dios su dios llamó a los dichos aztecas primero éste los llamó y después ellos lo tomaron por su dios\" Output: \"Auh yn achtopa chichimeca yn azteca yn oncan macehualli yn oncan huey altepetl yn oncan momanillito yn huey altepetl Aztlan auh quim\n",
      "Processed input 117: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Y según dijeron los españoles viejos desde que empezó a haber virreyes en México nunca se había visto que un virrey hiciera tal cosa como lo hizo don Juan de Mendoza y Luna marqués de Montesclaros\" Output: \"Auh ynic otlananquilli yn españoles huehuetque ynic ye huel ye quin mochiuh yn iteyacan ynic ye quinmoyecchiu yn don Juan de Mendoça mar\n",
      "Processed input 118: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Se siembran de a cinco a cuatro maicitos y luego se le pide a la Tierra y a nuestro Dios y se da muy bien\" Output: \"Se kitoka de macuilli ihuan ome maicitos ihuan ompa kitokaytia in Totecuyo ihuan toDios ihuan monequiz\"\n",
      "Processed input 119: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"pero no más en su casa ardía y no a media noche sino aun con un poco de sol cuando el sol ya está crecido cuando va cayendo el sol es cuando lo quemaban\" Output: \"pero amo zan nikan in caltzintli ya ihuan amo ipan nohuian in tonatiuh zan ye yehuatl yuhqui in ohtlatlacoltiloc yuhqui in tlat\n",
      "Processed input 120: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Muchas gracias\" Output: \"Cenca timotlapohua\"\n",
      "Processed input 121: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Cuando Tozanteuctli de Tlalmanalco y los guardianes de trojes que habían hablado mal supieron que los tlatoque de Chalco estaban por llegar salieron huyendo\" Output: \"Auh yn iquac yn oquimittacque yn Tozanteuhctli yn Tlalmanalco yhuan yn intlahtocauhque yn oncan chaneque ynic oncan quim\n",
      "Processed input 122: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Y así lo mandaron el juez governador y los juezes y se tome juramento en firmeza de lo mandado y se haga presente Pedro Gerónimo regidor mayor y Pedro de San Francisco regidor y así lo mandaron en firmeza de lo qual lo firmaron de sus nombres Antonio Valeriano Francisco Martin alcalde Miguel Sanchez juez Toribio Lucaz Pasó ante mí Leonardo escrivano\" Output: \"Auh yn ixpan juez governador yhuan juezesme ynic quichihua juramento ynic quimopalehuilia ynic niman quimotlanahuatillitia y Pan Pedro Jeron\n",
      "Processed input 123: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Les respondió Tezozomoctzin Os habéis fatigado mexicas habéis hecho bien\" Output: \"Oquinnotzato Teçoçomoctzi Auh in tla yehuatl in mexica in tlatzintlan in quimocaquilti\"\n",
      "Processed input 124: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"El domingo 26 de abril se llevaron para Castilla dos ocelotes de piedra que estaban en el tecpan de la comunidad\" Output: \"Axcan domingo yn ic 26 mani metztli abril yquac quimilhuique Castilla ynic omoteneuhque ocelotl oncan tecpan yn tlacpac altepetl\"\n",
      "Processed input 125: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"12 Calli 1257\" Output: \"XII Calli xihuitl 1257 años\"\n",
      "Processed input 126: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Si yo fuese\" Output: \"tla nejhua yejhua\"\n",
      "Processed input 127: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Su hijo ha bajadoen la primavera desciende allíes el Dador de la Vida\" Output: \"In iyahtic in inacayo achtoz in ixquichic xochimilol\"\n",
      "Processed input 128: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"los niños los ancianos\" Output: \"in piltzitzintin in tlacamej\"\n",
      "Processed input 129: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Por esta misma época desarrollaba sus actividades el famoso pintor español Bartolomé Esteban Murillo\" Output: \"Ipan inin in icuac on ye omotlaocoli in inacayo in icpac tlacatl chichimeca in tlacatl in hualquiztli in itoca Bartolomé Esteban\n",
      "Processed input 130: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"La piña es fría\" Output: \"In pinayotl cachi\"\n",
      "Processed input 131: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"El sábado 8 de diciembre de 1612 fiesta de la Concepción de Nuestra Señora en tiempos del comisario fray Juan Zurita con una procesión muy solemne los religiosos de San Francisco enterraron una pieza de oro en Santa María la Redonda en Cuepopan a fin de señalar el sitio en que se comenzaron a poner los cimientos para construir la nueva portería donde habría de decirse la misa mientras se construía el nuevo dormitorio y la nueva iglesia de los religiosos y cuando ya la iban a construir se demolió la iglesia vieja\" Output: \"Axcan sábado yc 8 mani metztli de diciembre de 1612 años yhcuac ypan ylhuitzin Concepción Nuestra Señora comisario fray Juan Zurita yn oquihualm\n",
      "Processed input 132: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"CIDRA\" Output: \"TOLKAK\"\n",
      "Processed input 133: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Allí se veía el cielo las estrellas el Mastelejo Y Motecuhzoma cuando lo vio lo tuvo a muy mal presagio cuando vio las estrellas y el Mastelejo\" Output: \"Nican oncan tlatlauhqui in huey cielo in istac in Mastelejo Auh in itoca Motecuzoma in oncan quito in yuhqui in istac in Mastelejo\n",
      "Processed input 134: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Lo venden por medidas\" Output: \"Tlen kikouaj in tlatoli\"\n",
      "Processed input 135: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Por los Tratados de Letrán se crea el Estado del Vaticano\" Output: \"Ipan in Inic Teopixcatilol Inic Teopixcatilol Ipan in Inic Teopixcatilol Ipan in Inic Teopixcatilol Inic Teopixcatilol\n",
      "Processed input 136: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"A uno lo ponía en Tetzcoco para que administrara los santos sacramentos a todos los españoles que allá vivían ya no les administrarían los santos sacramentos los frailes a quienes se quitaban los españoles debiendo dedicarse sólo a cuidar de los naturales\" Output: \"Auh in ye quimotlallilia Tetzcoco yn quimocahuilia yn quimohuicilia yhuan yn españolesme mochintin yn omoteneuhque tlamachtiltin yn\n",
      "Processed input 137: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Y el ropaje del cuello que lo envuelve una cosa parecida a la dalmática de papel con pintura y sus sandalias de hule esponjoso\" Output: \"Ihuan in itzintla in itzotzopaztli quimamaca in tlahtolli in ic quimamaca in ic tlapalxochitl in ic tequitl in t\n",
      "Processed input 138: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Ya me voy a su casa pereceré\" Output: \"Azo nic niquihto in camicohua nicpiaz\"\n",
      "Processed input 139: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Y cuando ya es totalmente de día se mete la gente se retrae El canto se dejaba a la hora de la comida\" Output: \"Ijcuac ye oc ye tonalli tlahuia niman ye on tlacuali quimimiloua In tlacualli ye on tlacuali\"\n",
      "Processed input 140: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Así pues cuando en este año los mexicas derrotaron a los tepanecas coyohuacas pereció la ciudad de Coyohuacan\" Output: \"Auh ynin in yn omoteneuh xihuitl ynic quinpeuhque yn mexica yn tepaneca coyohuaca yn oncan quinpeuhque altepetl Coyohuacan\"\n",
      "Processed input 141: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Termina el año 2 Calli\" Output: \"Tlen yei Calli xihuitl\"\n",
      "Processed input 142: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Este Huetzin ambicionaba el señorío de Colhuacan porque de aquí era originaria su madre la señora Coátetl en la cual lo había engendrado el tlatohuani de Cohuatlichan llamado Itzmitl y también por otro nombre Tlacoxinqui éste fue el primer tlatohuani de Cohuatlichan\" Output: \"Inin Huetzin quinecemi in itlahtocayo Culhuacan ca yehuatl in ipiltzin in inantzin catca Culhuacan in itlahtocauh catca yn it\n",
      "Processed input 143: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"La qual tiene en largo ochenta baras y de ancho tiene otras tantas las quales os vendemos por prescio de veynte y seys pesos los quales nos diste yo el dicho don Baltasar Tlilancalqui y la dicha mi muger Juana Tlaco\" Output: \"Yn iquac yn ixquichpa mocuicac ca huiac cenpohualmatl yhuan huiac occequi ca huiac onmatl ypanpa quinamacac macu\n",
      "Processed input 144: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Su fruto se come es muy sabroso\" Output: \"Se kikua in itakka maj oksi\"\n",
      "Processed input 145: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Los verdaderos mexicas mis nietospermanecen en fila se mantienen firmeshacen resonar los tamboresla flor de los escudos permanece en vuestras manos\" Output: \"In cuix yuhqui yn mexica in inantzin nonotzaltzinti in quauhquehuic quauhmatlalli xiquihtotia\"\n",
      "Processed input 146: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"No alterarse nunca es una gran muestra de autodominación completa\" Output: \"Amo on ximotlatoca amo mocneliloz\"\n",
      "Processed input 147: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"de modo que no tuvieron por preciosa ni su cabeza ni su pecho no dejaron de tomar no alcanzaron en vano y vieron logrado el señorío la veteranidad con que rigieron y gobernaron con eso se hicieron dueños del dominio y el gobierno de los traficantes\" Output: \"in aocacque zan in quiquimacacque zan iui in icpac in iquac in quimocauhque in quimomahuizohua in quimotlalilhuia in\n",
      "Processed input 148: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"La fruta se usa para comer y también para remedio\" Output: \"In se kikua para se kikua uan no kualtia para se tein chikauaya\"\n",
      "Processed input 149: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"1\tmanojito de epazote\" Output: \"Ce manojti epazotl\"\n",
      "Processed input 150: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Los antiguos mexicas tuvieron que venderse y por eso se dice que se metieron al madero es decir a la collera de madera con que eran llevados a todos los pueblos\" Output: \"Auh yn oquinnihualmotlatlauhtiliaque ynic quihualmocuepque yn huehuetque mexica ca yuh mochihuato ca yuh quimotenehuiliaya\n",
      "Processed input 151: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"El lunes 13 de enero de 1614 por la mañana dio a luz la señora marquesa y virreina doña Mariana Riederer quien tuvo una hija que luego se llamó doña Brianda la cual era la segunda hija nacida en la ciudad de México del señor virrey don Diego Fernández de Córdoba marqués de Guadalcázar\" Output: \"Lunes yn ic 13 mani metztli henero de 1614 años yhcuac huel ypan tlaxillacalli yn ilhuicac teoyotica tlahtohuani doña Mar\n",
      "Processed input 152: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Canto de la huida\" Output: \"Canto de huida\"\n",
      "Processed input 153: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Al día siguiente 17 de abril martes santo en las orillas de San Antón Xoloco se dispusieron sobre la calzada muchos soldados españoles con sus armas para vigilar también se dispusieron muchos soldados sobre la calzada del Tepeyac que pasa por Coyonacazco también se dispusieron muchos soldados sobre la calzada que va a Chapultepec donde acaban las casas junto a la cruz de plomo se puso asimismo vigilancia en todas las calzadas que entran a la ciudad de México y en todos los caseríos que rodean a la ciudad de México\" Output: \"Auh yn ipan in ylhuitzin Sancto Antón Xoloco martes santo yn ipan calzada quahuitl oncan monequiz yn españolesme yn itlaquen yn oncan qu\n",
      "Processed input 154: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Y tendrás que llegar tendrás que acercarte tendrás que enfrentarte con aguas tremendas que van retumbando que van haciendo estrépito que dan retumbos al correr\" Output: \"Ihuan ticahua ticahualo ticahualiztica in cenca tehuiztica in cenca tlahuiztica inic tetecaco inic tetecozque inic tetepitzauhque\n",
      "Processed input 155: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"El día de la fiesta de San Juan Bautista comenzó un fuerte aguacero que estuvo cayendo día y noche sobre toda la Nueva España de modo que la ciudad de México se llenó nuevamente de agua toda la parte de Ahuatzalpan quedó convertida en una gran laguna y todas las chinampas se inundaron y se perdieron\" Output: \"Ipan in yehuatl in San Juan Bautista yquac peuh cemilhuitl tlahuiyacatl ye tlatlato in ipan altepetl Nueva España auh in altepet\n",
      "Processed input 156: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Llegará mañana\" Output: \"Moztla on moquetz\"\n",
      "Processed input 157: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Acaso alguien acaso no todos nosotros daremos alegría haremos feliz al Inventor de sí mismo\" Output: \"Zan quen tla in tataztlacatl zan tla zan totataztlacatl titlaocoxca titlaocoxca in itlahtocauh\"\n",
      "Processed input 158: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Cuando murió Tlotépetl los mexicas pusieron a Cuauhtliquetzqui para que los acaudillara\" Output: \"Yn oyuh omic Tlotepetl quinmahuiztililique yn Quauhtliquetzqui yehuatl quinmahuiztililique yn mexica\"\n",
      "Processed input 159: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Florece en agosto\" Output: \"Xochiyoua en agosto\"\n",
      "Processed input 160: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Si tal vez un pájaro el que va a salir del metal precioso así se tallará así se raspará el carbón de suerte que adquiera sus plumas sus alas su cola sus patas\" Output: \"Icuac in ic ual mottotonia in tlalticpac in tetepitzin cuahuitl yece yece ca in quimototonia in cuahuitl in quauhtli in quetz\n",
      "Processed input 161: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Hay tres plantas parecidas  a una le dicen xokoyole a otra le dicen tecose y a la otra pesojxokoyolin\" Output: \"Onkak yej  chikauaya taman se kitokaj xokoyolejsej se kitokaj tecosej uan se kitokaj pesojxokoyolin\"\n",
      "Processed input 162: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Testigo Toribio Chichimecatl vezino del barrio de San Sebastian Zacatla de hedad de setenta y cinco sic pro setenta y nueve años el qual después de aver jurado en forma de derecho por dios nuestro señor e por Santa Maria e por una señal de cruz y si miente su alma se la llevará el diablo\" Output: \"Testigo Toribio Chichimecatl ychan San Sebastian Zacatla ynic omonamicti caxtolli onpohualxihuitl ychpuchca ypan matlactli yep\n",
      "Processed input 163: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Veintiocho centavos para una carta simple que no pese más de cinco grumos\" Output: \"Cempoalli huan ome centavos para se tlaaliliztli yeuatl yeuatl in nacaztli\"\n",
      "Processed input 164: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Así fue como comenzaron la guerra ésta comenzó porque Maxtlaton tlatohuani de Azcapotzalco les pidió que le llevaran una chinampa\" Output: \"Izca yc pehua y ye quinpeuh yn ipan yancuican yn peuh yn Maxtlaton tlahtohuani Azcapotzalco quimilhuia yn quinpeuh\n",
      "Processed input 165: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"mandaron que se quedase así hasta ver si avia alguien que dixese otra cosa sobre las casas y tierras y asi lo mandaron y firmaron Antonio Baleriano Miguel de los Angeles alcalde Martin Juares alcalde Pasó ante mí Francisco Maldonado escrivano\" Output: \"Oquito yniquanque hasta quimottilizque yn aquin quitemachiztiz yn ical yn tlalli ynic niman oquimottilizque yn intocatzinco nican oqu\n",
      "Processed input 166: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Cuando en el día viernes mencionado fue cubierta por la Luna la faz del Sol eso es lo que antes se llamaba el Sol fue comido\" Output: \"Auh yn iquac in tonatiuh yn iquac yohualtica tonatiuh yehuatl yn iuh quimochihuilli yn itzonteco yehuatl yn tonatiuh yuh qu\n",
      "Processed input 167: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Ante su rostro saldremos quizá habrá de irritarse allá en Huexotzinco Xayacamachan en Tetzmolocan Yo mujer me unté las manos con ungüentos me acerco con mi falda de fruto espinoso con mi camisa de fruto espinoso Los veré a todos perecer Deseo en Xaltepetlapan a los huexotzincas al cautivo de Cuetlaxtlan a los traviesos cuetlaxtecas los veré a todos perecer De qué modo se sabe Me llama el niño el señor el pequeño Axayácatl quiere conmigo lograr su placer Por mi causa a dos tendrás que cuidar niñito mío\" Output: \"Yn iquac tleco nixpantzinco tla oc quimilnamiqui in Huexotzinco Xayacamachan in Tetzmolocan Niquinnamiqui nicxot\n",
      "Processed input 168: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Las tres clases sirven para hacer panela\" Output: \"Ipan yej yeyi taman panela mochipa se kipixkuoujtaj\"\n",
      "Processed input 169: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"1 manojito de cilantro\" Output: \"Ce cuahuitl iltzopeliloni\"\n",
      "Processed input 170: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"8 Tochtli 1474\" Output: \"VIII Tochtli xihuitl 1474\"\n",
      "Processed input 171: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"En este año los mexicas tenían 45 años de estar en Tenochtitlan desde que llegaron los chichimecas mexitin colhuas\" Output: \"Ypan in inxiuhtlamantli ye iuh nepa cenpohuallonchicome xihuitl ynic oncan quinhualyacan yn Tenochtitlan yn mexica chichimeca\n",
      "Processed input 172: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"11 Calli 1477\" Output: \"XI Calli xihuitl 1477\"\n",
      "Processed input 173: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Después de que Cuauhtémoc fue entregado lo llevaron a Acachinanco ya de noche Pero al siguiente día cuando había ya un poco de sol nuevamente vinieron muchos españoles También era su final Iban armados de guerra con cotas y con cascos de metal pero ninguno con espada ninguno con su escudo\" Output: \"Ipehualhui in Cuauhtemoc ipan acocohque niman ye yiman tlatecpantli oncan quiyahuititiqui Ayc Acachinanco Nozo ye yiman ompe\n",
      "Processed input 174: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Quizá es designio de Huitzilopochtli que nada suceda\" Output: \"Iuhqui itla yehua in Huitzilopochtli yuhqui in amo nelli\"\n",
      "Processed input 175: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Entonces perecieron los toltitlancalcas\" Output: \"Ye yquac pehua in toiltitlanca\"\n",
      "Processed input 176: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"lo que está aquí\" Output: \"oncan\"\n",
      "Processed input 177: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Les dijo Quetzalcanauhtli Se ha compadecido de vosotros vuestro dios y señor partamos\" Output: \"Quetzalcanauhtli oquimolhuili Inic nontlatlauhtia in amotlacatl in ahtle totatzin titocuacanazque\"\n",
      "Processed input 178: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"El tiene corbatas blancas y azules\" Output: \"Yehua quinmahuiztililia cuahuitl quimacahuahtin\"\n",
      "Processed input 179: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"vendieses\" Output: \"titlanamacaz\"\n",
      "Processed input 180: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Les replicaron los chalcas acxotecas Está bien os acompañaremos\" Output: \"Quinon oquimilhuique yn chalca acxoteca Quenmanazque tiazque\"\n",
      "Processed input 181: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Se compadecieron de ellos y Atonaltzin les cedió una de sus tierras muy grande también Cuahuitzatzin les cedió una de sus tierras la cual se extendía desde el patio del Diablo hasta la cerca de los tenancas en Tecuanipan\" Output: \"Auh ynic quintlaxtlauhque quimohuillique yn Atonaltzin yhuan quinmacac yn itlaquen ynic mochi huey yn Quahuitzatzin ynic\n",
      "Processed input 182: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Por eso es mejor no sobreestimar acontecimientos desagradables\" Output: \"Ihuan amo cualli monechicaz tlen on ye huehuetztia itlaqualantia\"\n",
      "Processed input 183: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Al frente marchaban cuatro estandartes negros dos iban enmedio con su cruz de plata y a los lados los otros dos con su cruz de madera dorada\" Output: \"Auh yn achtopa ye omoteneuhque quauhtin estandartes tlaquentin yehuantin ome tlatzopinalli yn icruztin de plata yn icruztin de\n",
      "Processed input 184: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Todas son yerbas xiuit\" Output: \"Nochi xiuit\"\n",
      "Processed input 185: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"12 Tochtli 1322\" Output: \"XII Tochtli xihuitl 1322\"\n",
      "Processed input 186: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Allí donde limpian el terreno para la siembra del frijol después de la cosecha empiezan a brotar los hongos\" Output: \"In onkan tlamachilhuia in ixtlahuacalpan in ixtlahuacan niman ye icuac ye yaua in tlapaltoton\"\n",
      "Processed input 187: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"12 cebolla mediana\" Output: \"Chicuey xonacatl\"\n",
      "Processed input 188: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"44\tY bien canta bien habla bien conversa bien responde bien ruega la palabra no es algo que se compre No como muda tonta te vuelvas Y el huzo la tablilla para tejer hazte cargo de ellos la labor lo que eleva asciende como el olor lo que es la nobleza el merecimiento los libros de pintura lo que es un modelo el color rojo el saber Así bien al lado y junto de la gente vivirás así merecerás en alguna parte un poquito de bebida de maíz una tortilla doblada una verdurita un nopalito y en alguna parte algo de granito maíz añublado lo que de tu cadera que de tu pecho colgará para que tome calor para que tome tibieza tu cuerpo para que de este modo agradezcas al Señor Nuestro su misericordia con las gentes su benevolencia con las personas\" Output: \"44\tAuh ca tla ic tihuiyac in tihuitz in tihuehuetz in tihualhuihcauh in tihualhuitlauh in tiquittaz in t\n",
      "Processed input 189: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Así todo cuando ya tenía todo preparado lo que se mencionó y se dijo luego partía a Tuchtepec Allá están en detención los traficantes los comerciantes embozados de todos los pueblos gente de todos los rumbos allí tenían una morada común\" Output: \"Ihcuac ye quipia nochi oquicuic oquicuilli ihquac oconanque niman oquimilhuique ynic niman ye onacito Tuchtepec Ca\n",
      "Processed input 190: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Así pues en este año comenzó a solicitar la licencia y la ayuda de los reyes don Fernando y doña Isabel para venir a la Nueva España a fin de venir a descubrir nuevas tierras que pertenecieran a los reyes de España\" Output: \"Ipan inin xihuitl omoceloc in tequitl in quinmelahuac in itlanahuatilhuan in reyes don Fernando yhuan doña Isabel in ipan Nueva España inin\n",
      "Processed input 191: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Se dice que cuando llegó acá el merecedor de tierras de los tecuanipantlacas el llamado Tziuhtlacauhqui la mujer que éste traía consigo ya era manceba de Tliltécatl ya venía encinta y en su vientre traía al hijo de Tliltécatl hermano mayor de Atonaltzin y que bajaron de Huexotzinco\" Output: \"Auh ynic oncan auh ynic oncan quihualmomaquilli yn tlacatl yn Tziuhtlacauhqui yn omoteneuh tecuanipan tlaca ynin yehuatl\n",
      "Processed input 192: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"También en el año 1 Tochtli los mexicas le pidieron a Tezozomoctzin un hijo suyo para que los gobernara le dijeron Señor tlatoani tus siervos los ancianos mexicas nos han enviado para decirte Escuche el señor Tus pobres nietos quieren tener un señor danos tu collar y tu pluma de quetzal\" Output: \"Auh yn ipan Ce Tochtli xihuitl yn iquac oquimotlachcuitlalli yn mexica Teçoçomoctzi ce conetl quinmotlatlauhtilli qu\n",
      "Processed input 193: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Los españoles también quemaron leña sobre sus casas por toda la ciudad y repicaron las campanas en todas las iglesias y monasterios de México\" Output: \"Auh ye quicuacuaca quincuacaque in caltepitlan in cemecoliztli in huey altepetl in ipan in ixquich tlacpac otlacuacu\n",
      "Processed input 194: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Si está en el cafetal lo limpian pero en el monte nadie lo limpia\" Output: \"Se kampa kajfentaj pero kampa iteyo amo se kipajtia\"\n",
      "Processed input 195: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"La vecina tiene una casa\" Output: \"Inon puchteca ce caltin quimocuitlaxilia\"\n",
      "Processed input 196: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Ni en el año 8 Técpatl 1448\" Output: \"Auh no ypan VIII Tecpatl xihuitl 1448 años\"\n",
      "Processed input 197: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"En este año los mexicas derrotaron a los de Xicochimalco también entonces derrotaron a los de Xaltépec y a los de Totomihuacan\" Output: \"Ye yquac yn ipan in xihuitl quinpehualtique mexica yn Xicochimalco tlaca yn oquinyacanque yn Xaltpec tlaca yn Totomihuacan tl\n",
      "Processed input 198: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"El loro está sobre el arbolito\" Output: \"In totonal yaxca\"\n",
      "Processed input 199: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Finalmente cuando llegó el momento en que se haría de noche a las 2 y media de la tarde las nubes comenzaron a moverse y a dejar libre al Sol para que todos pudieran ver lo que le iba a ocurrir al Sol las nubes se alejaron un poco por todas partes se dispusieron alrededor en círculo y una vez que se retiraron se aclaró el cielo para que el Sol estuviera solo en el centro\" Output: \"Auh yn iquac ye yohualtica ynic yohuatzinco yez yohualtica ommomoztlayohua ynic moquetzaya yn qualli yn itzon ynic moch\n",
      "Processed input 200: Instruction: \"Traduce el siguiente texto a Nahuatl\" Input: \"Y que a cabo dos meses que andan en el pleito todo el tiempo en que terminó la información etc\" Output: \"Auh in icuac ye tlamico inin metztli in oncan tlatolli in ic tlatolli inic tlatolli\"\n",
      "Embeddings guardados en output_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import csv\n",
    "\n",
    "def process_dataset(dataset_path, model, tokenizer, max_seq_length=256, max_new_tokens=50, output_csv='output_embeddings.csv'):\n",
    "    # Cargar el dataset y seleccionar los primeros 20 inputs\n",
    "    dataset = pd.read_csv(dataset_path)\n",
    "    selected_inputs = dataset.head(200)\n",
    "\n",
    "    # Lista para almacenar los embeddings de salida\n",
    "    all_output_embeddings = []\n",
    "\n",
    "    # Iterar sobre los primeros 20 inputs del dataset\n",
    "    for index, row in selected_inputs.iterrows():\n",
    "        prompt = {\n",
    "            \"instruction\": row.get(\"instruction\", \"Translate to Nahuatl\"),  # Ajustar según la columna de instrucciones en el CSV\n",
    "            \"input\": row.get(\"input\", \"\")\n",
    "        }\n",
    "\n",
    "        # Generar los embeddings del output\n",
    "        output_embeddings, generated_text = get_output_embeddings(prompt, model, tokenizer, max_seq_length, max_new_tokens)\n",
    "        \n",
    "        # Agregar los embeddings a la lista\n",
    "        all_output_embeddings.append(output_embeddings.flatten())\n",
    "\n",
    "        print(f\"Processed input {index + 1}: {generated_text}\")\n",
    "\n",
    "    # Guardar los embeddings de salida en un nuevo archivo CSV\n",
    "    output_df = pd.DataFrame(all_output_embeddings)\n",
    "    output_df.to_csv(output_csv, index=False, header=False)\n",
    "    print(f\"Embeddings guardados en {output_csv}\")\n",
    "\n",
    "# Ejecutar la función para procesar el dataset y guardar los embeddings\n",
    "process_dataset('dataset.csv', model, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed input 1: \"Auh in ye yuhqui in on tlenamacac niman ye ic teixpan on motlalia ce tlacatl itech mocaua\"\n",
      "Processed input 2: \"In chalchihuitl teocuitlatl mach ah ca on yaz\"\n",
      "Processed input 3: \"Auh yn oyuh in yoca hualmotlalli tonatiuh ylhuicatitech niman yc peuh yn huel ye tlacoçahuia çan ihuiantzin ye tlayohuatiuh ynic ye poliuhtiuh tonatiuh ynic huel ixpan  147 ye yatiuh ynic huel ixpan ye onmomana metztli huel cacitimoman ynic yahualtic tonatiuh ynic quixtzacuilli y çan ihuiantzin huel onpolihuico tonatiuh\"\n",
      "Processed input 4: \"Yn oncan mohuicatza yhuan yn ciudad cabildo tlaca yhuan oydores Audiencia Real tlacan quinepantlahuitiaque yn tlahtocacorona real quinapalotia ce tlacatl coxín ypan mantia çan ye ynmamanian yn mantiaque\"\n",
      "Processed input 5: \"Kualtia\"\n",
      "Processed input 6: \"Auh ynin ca huel yehuatl quimocenteotia  31r yn huey tlacatecolotl ma cenca quinmicnelli ma quinpalehui ma quinmaquixti ynic amo mochtin quinmictizque ynic amo quincenpopolozque ma cana occeccan quinhuica ma cana cualcan yeccan quintlalmaca yn oncan cenca quixcahuizque ynic quitlaecoltizque\"\n",
      "Processed input 7: \"Yhuan occe cavallero ytoca don Francisco de Cardona comendador de Montesa no chichiltic cruz çan ixquich nepaniuhqui yn icomienda quitlalia no umpa hualla yn España ynin nican injuez mochihuaco yn obrajeros\"\n",
      "Processed input 8: \"Inin tlacatl cemi tlatquihua\"\n",
      "Processed input 9: \"Ypan in motlahtocatlalli yn Tziuhtecatl yn Colhuacan tlahtohuani\"\n",
      "Processed input 10: \"In monamaka Kuesalan\"\n",
      "Processed input 11: \"Sayoj se taman\"\n",
      "Processed input 12: \"Amo ximotomintema intla amo cualyotica tictlani\"\n",
      "Processed input 13: \"Kuali se kikua maj se kiteuatsa itech komal\"\n",
      "Processed input 14: \"Mochiua ne Kalikampa Texayakatitan kuoujtaj kajfentaj uan amo kiteximaj por in se kikua itakka\"\n",
      "Processed input 15: \"VI Tochtli xihuitl 1602 años\"\n",
      "Processed input 16: \"In nanacatl cualli mochipahua ihuan motetequi in ahmo huey in tlatetectli in yepazohtli mocuihcuilia in iatlapalton ihuan mochinin motlalia comalpa in ahmo huel totonqui motlalilia in iztatl ixquich in monequiz ihuan in chilcuitlaxcolli ahnozo chiltlaixtlapantli motlapachoa ica zoquicaxitl ixquichcauh in ye tlahuicxitilli Achiuhqui muchipa motlaxcaltlapiccua\"\n",
      "Processed input 17: \"Nican ypan in in ya huitze yn Mexico Tenochtitlan yn cuezconpiaya yn Amaquemecan quinonotzaco yn tlacateuhctli yn Itzcohuatzin yn iquac yn ayemo tlahtohuani ca çan oc tlahtocapilli y nican Mexico auh ca yehuatl tlahtocati yn Huitzillihuitl yn teomeca yn iuhqui ytoca yn auh ytlan teuhctlahtohua yn Quatlecohuatl tlacochcalcati\"\n",
      "Processed input 18: \"Se da donde se siembra como en las milpas\"\n",
      "Processed input 19: \"Auh in yehuatl yn Cohuaçacatzin ca occenca piltzintli yn iquac ayamo yehuatl quichichiuhque çan yehuatl quichichiuhque yn cihuapilli yn inantzin yn Cohuaçacatzin ytoca yn cihuapilli Tlacocihuatzin contlallilique yn teuhctzontli yhuan yn xihuitzolli yhuan yn ixquichtlamantli tlahtocayotl conmamacaque yn cihuapilli\"\n",
      "Processed input 20: \"Yn oyuh omotlali yntlatocauh Quaquauhtzi yn oquimopeuh chimalhuaca\"\n",
      "Processed input 21: \"Oquito yn testigo ca uel melaoac ynic onoconan juramento ynic onitlatolmelauh yn ye ninemi tlalticpac ye napoalxiuitl auh ynic nicneltilia notlatol zan onictlatlauhti in escribano nopampa quitlalia notoca yoan nofirma ypampa amo nicmati nitlacuiloz don Gaspar de Mendoza Pedro Daniel nixpan Francisco Millan escrivano\"\n",
      "Processed input 22: \"Caxtilyacanqui zan niman oquiztihuetz in ihuicpa MexicoTenochtitlan oya Chalchiuhcuecan quicalito tlacatl in yancuican acic\"\n",
      "Processed input 23: \"in chakaykuoujkamoj uan istakkuoujkamoj\"\n",
      "Processed input 24: \"In cihuatequipano oquintlalli nahui tlatecontin ipan ahcopechtli\"\n",
      "Processed input 25: \"Ipan matlactli omome tecpatl xihuitl oyaque mexicah Tecpayocan\"\n",
      "Processed input 26: \"In tlatolmatinime auh in intequiuh in quimocuitlauia in copaltemaliztli in tlenamaquiliztli in huitztli in acxoyatl in necoliztlili\"\n",
      "Processed input 27: \"Tla nicnamacazquia in callí ayocmo tlen nohuaxca nicpiazquia\"\n",
      "Processed input 28: \"Yn oonehuaque motlalito Acueco quimopeuito omotlalito Teucalhuiaca onehoaque Çoltepec onehuaque unca motlalito Tepotzotla onehuaque omotlalito Citlaltepec onehoaque motlalito Temazcalapa unca namicoque macoque totolli totoltetl tlaolli uncan yyocuitiloque\"\n",
      "Processed input 29: \"In kilit\"\n",
      "Processed input 30: \"Chilcuitlaxcolli\"\n",
      "Processed input 31: \"Auh yhuan ya yepohualxihuitl ypan caxtollomome xihuitl yn ipan 1 Tecpatl xihuitl 1532 años yn omotlalli yn oquauhtlahto yn don Pablo Xochiquentzin yquac axihuaco Mexico ya yexiuhtica ynic ompa huillohuaya Teoculhuacan\"\n",
      "Processed input 32: \"Mochiua kuoujtaj uan kajfentaj\"\n",
      "Processed input 33: \"tlacoapan a itemoya\"\n",
      "Processed input 34: \"77\tNopiltzine ma ximehuititie at oncanin in cuelachitzinca in cemilhuitzin in ticmochielitica in itetzin in iquauhtzin in itemotzin in iehecatzin in Totecuiyo In ipan iatzin itepetzin in tocommomatemilitinemi in choquiztli in ixayotzintli in cemilhuitl in ce yohual In aihuiyan in ahicemele in tihualmehua in tihualiza ahmo ihuiyan ahmo icemele in cochiztli in netequiztli in ticmuchihuilia In tepaltzinco in tenahuactzinco in zan motzontlantzinco temi immocaczoltzin immotopiltzin auh immohuacaltzin immotlamatzohualtzin immohuictzin immomecapaltzin inic omitztenyoti inic omitzmahuizzoti in Totecuiyo In tiquauhtli in tocelotl immolhuil immomacehual In titiacauh in titecuicauh In xamitl impololli in cacaxtli in topilli in huictli immecapalli inic ticmopalehuilia in atl in tepetl in petlatl in ycpalli inic titlacazcaltia inic titlacahuapahua inic huel tetloctzinco tenahuactzinco timehuititica Ma cenca itlantzinco ximaquilti immocacatzin immotopiltzin immohuictzin immomecapaltzin\"\n",
      "Processed input 35: \"Yn ipan axcan domingo yc XVIII mani metztli de julio de 1593 años yquac hualmohuicaque mocallaquico in Sant Juan de la Penitencia yn cihuapipiltin monjastin Sancta Clara ypilhuantzitzin çan oc macuiltin yn hualmohuicaque ye teotlac in mocallaquico otzillin nahui ora\"\n",
      "Processed input 36: \"Auh no oncan in yn omoteneuh Tiçayocan oncan quichihuaco quitlacatillico yn Tlaquilxochtzin Tzompanco cihuapilli ce yconetzin oquichtli oquitocayotique Huehue Huitzilihuitl ynin ça ce mexica chichimeca yn ithatzin mochiuh\"\n",
      "Processed input 37: \"yn nican ciudad Mexico Tenochtitlan yn ipan cemilhuitl jueves cempohuali ommacuilli yn meztli de setiembre de 1586 años yn nehuatl alcalde Miguel de los Angeles justicia tictocuitlahuiya yn icatzinco su magestad audiencia\"\n",
      "Processed input 38: \"In xochiyoua agosto ijuak in chikauaya ta in por tiempo saj in onkak amo nochipa\"\n",
      "Processed input 39: \"Ualleuaque omotlalico Apazco motlalmomoztique ye yuh oxiuhtia uncan mic Apantecuhtli niman contlalique Citlal yexiuhtique\"\n",
      "Processed input 40: \" yn Teocolhuacan yn inahuac Aztlan yn huehuetque chichimeca yn totollinpaneca yn axcan ye yntoca amaquemeque ynic ompa huecahuaque ontzonxihuitl ypan caxtolpohualxixihuitl ypan yepohualxihuitl ynic niman ye huallolinque ynic hualnenenque\"\n",
      "Processed input 41: \"VIII Tecpatl xihuitl 1500 años\"\n",
      "Processed input 42: \"Yuan ylhuiloc yn testico que ticmati cuix ica onpa otlalchiuaya yn Toltecatl yciuauh catca quito yn testigo zan techtlapololtiya ca yaquin oxihuitl yn onpa ouetzico auh amo ticmati quenin onpa mocuentiya ca za niman yuh nicmati yn tlali in itech poui yn Atlixeliuhqui ocayuiny nocomati\"\n",
      "Processed input 43: \"Axcan ycce domingo quaresma yn ic 24 mani metztli febrero de 1613 años huel ypan ylhuitzin Sant Matía ye teotlac ynic nican Mexico onmopehualti ynic ompa mohuica la ciudad de los Ángeles Cuitlaxcohuapan yn tlahtohuani señor el licenciado don Pedro de Otálora presidente yn Audiencia Real Mexico ynic ompa mohuica moteochiuhtzinoz ynic teopixqui clérigo mochiuhtzinohua yhuan yca umpa yc moteochiuhtzinoz yn epístola yhuan evangelio yhuan yn missa yc quimochihuiliz çan oppa yc quimoteochihuiliz yn ipan in ce cuaresma yn obispo don Alonso de la Mota y Escobar yuh quihualmonahuatilia yn Sancto Padre çan eilhuitl mochiuaz auh macihui yn iuh catca yn nahuatilli ca ye quin ipan domíniga yn Passión tlamico yn ineteochihualitzin ynic missa quimochihuillico\"\n",
      "Processed input 44: \"Auh yn quincauhtia yn ipilhuan macuiltin yn icce ytoca Acolnahuacatl Tzacualcatl ynin oncan quihuallatocatlalli yn Tlacopan yn icome ytoca Quaquapitzahuac ynin oncan quihuallatocatlalli yn Tlatillolco yn icyey ytoca Epcohuatzin ynin ompa contlahtocatlalli yn Atlacuihuayan yn icnahui ytoca Maxtlatzin ynin ompa contlahtocatlalli yn Coyohuacan yn icmacuilli ychpoch ytoca Ayauhcihuatl ynin conmitlani yn Huitzillihuitl yn tlahtohuani nican Tenochtitlan yniqu iz quichihuaco yn tlahtocapilli Chimalpopoca\"\n",
      "Processed input 45: \"IIII Tecpatl xihuitl 1340\"\n",
      "Processed input 46: \"aocmo uel quicua in nelli mach quincuitlahuiltia za yuh qui nentlamati in inyollo za ye quimaticate in immiquiz\"\n",
      "Processed input 47: \"Ye hui ya motlacahuani xi huiti xi huiti ai Ometeotl in teyocoyani Tezcatlanextia\"\n",
      "Processed input 48: \"In toltecatl tlamachtilli tolin centzon aman In cualli toltecatl mozcaliani mozcalia mihmati moyolnonotzani tlalnamiquini\"\n",
      "Processed input 49: \"Quito Tla xihualauh tla xiccaqui çan ihuiantzin xiquito quezquintin yn otiquinmicti teteo soldatosme\"\n",
      "Processed input 50: \"Auh occequintin huehuetque tlaçopipiltin yuh quitotihui yuh quimachiyotitihui ca yuh quicuillotihui yn imamoxtlacuilolpa quilmach yn ihquac yazquia Quauhnahuac yhuan Michhuacan quilmach ayemo tlalmacehuaya ayemo quiquetzaya yn ixquich ynquaxoch yn imomextin omoteneuhque tlahtoque yn Atonaltzin yhuan Quahuitzatzin\"\n",
      "Processed input 51: \"In mocnin yonicontiac\"\n",
      "Processed input 52: \"Onkak ome taman chaluij tein nikan mochiua uan tein kuoujtaj mochiua\"\n",
      "Processed input 53: \"toh\"\n",
      "Processed input 54: \"Quenin mochihua\"\n",
      "Processed input 55: \"Auh in itzonnepilhuaz tlatlapalicpatl chichiltic coztic texotli tliltic Iztac ihuitl in ic tlamalinticatca\"\n",
      "Processed input 56: \"In tlailii ye huehca mitihuitz ompa toaltepepan yehuatl in tepachnecuhtli in mochihua yuhquin nican mihtoa in aniz ihuan canela tlatzicuehualli motlalia ihtic in tilmapoxacton cualli tlatzacuhtli inin maquia ihtic in comitl ica macuilli litro atl in cuacualacaz miec minuto Zatepan moteci in patlahuacchilli ihuan mocuacuachhuia ipan atl in ye pozontoc ihuan motlalilia piloncillo inin moneneloa ahzo ica chicuey litro necuhtli ma itztia ihuan ye huel miz\"\n",
      "Processed input 57: \"In iujki kitokaytiaj por in uitsyoj\"\n",
      "Processed input 58: \"In can ahmiccohua\"\n",
      "Processed input 59: \"Yey Acatl yc motlatocatlalli Uitziliuitzi Tenochtitla\"\n",
      "Processed input 60: \"Quemahcatzin Nicnequi cente calxelolli nictlaquehuiz Tlatimonequitia ximopanolti ximotiliqui\"\n",
      "Processed input 61: \"Yhuan yn ipan in cenca quiyauh yc mochiuh  98r yn tonacayotl\"\n",
      "Processed input 62: \"Ximohtalhui Aquin tlahtohua\"\n",
      "Processed input 63: \"83\tAuh intla otitlaellelaxiti ca ahmo tetlan tenahuac tinemiz ca niman titotocoz tiquixtiloz yc tiquintochtiliz tiquimmazatiliz immocihuauh immopilhuan Acan mochan acan mocal ihtic tiquittaz vmpa onquizaz in ycnoyotl in tctoneuh in techichinatz acan monopal acan monecuh tiquitztiaz Inda yuh ticchihuaz intla yuh tinemiz zan monehuiyan ticmottitiz in tecoco in tetoneuh in techichinatz zan monehuiyan itlan timocalaquiz in tzotzomatli immaxtlazolli zan monehuiyan ticmocuiliz in ahmo qualli in ahmo yectli in tlahuelilocayotl in teahuilquixti in tetlahuelilocatili in ahmo tetlacamachiliztli in tzonteyotl\"\n",
      "Processed input 64: \"Amo quinequi ynic cecen clérigos ye quinmihualiznequi nohuiyampa ypan arçobispado motlalitihui contratición yc ye quichihua yn frayles ach quen tzonquiçaz yn inneteylhuil tla oc yehuatzin quimomachiltia yn totecuiyo Dios ca oc ye nemi yn tlahtolli\"\n",
      "Processed input 65: \"\tAuh in ihcuac tlanauatiaya Moteoczomatzin in zazo campa calaquia pochteca oztomeca in teocnenemizque intla ompa impan oualmotzaoc intla onmiquito in oacmo quiuel caquilia itlahtul Moteoczomatzin\"\n",
      "Processed input 66: \"Auh yn inteyacancauh ocatca yn itoca Huitzilopochtli yn hueytlacatecolopixqui ytetlaecolticauh y huey tlacatecolotl Tetzauhteotl cenca quitlacanotzaya quimottitiaya yn Huitzilopochtli ynic çatepan oquimixpitlati yn Tetzauhteotl ynic ça ytoca mochiuh Huitzilopochtli\"\n",
      "Processed input 67: \"Cemi cuacualtzin motah ahuiliztica patlanih in yahualol cuameh ihuan xochimeh\"\n",
      "Processed input 68: \"O yhuin in y motlamaniltilia yn intlatecpanpantzinco tlaçoteopixque ma yuh mochi tlacatl quimati ca yuh quinmottilizque intla quimonequiltitzinoz ytla itlanequiliztzin totecuiyo Dios ca hualmohuicazque tiquihtotilizque yn nican San Antón Mexico Nueva España auh ytlacamo ytlanequilizticatzinco mochihuaz totecuiyo Dios ca amo huel hualmohuicazque\"\n",
      "Processed input 69: \"Ic niman ipan chicome tecpatl xihuitl oacique mexitin Amalinalpan in tlein itech pohui Azcapotzalco itlahtocayotzin\"\n",
      "Processed input 70: \"Yn ihcuac yn yn ompa ohualquizque Huehuetlapallan Nonohualco yn nonohualca teotlixca tlacochcalca tecpantlaca yn ipan in omoteneuh Ce Tecpatl xihuitl 1272 años yc niman ohualnenenque yn tzihuactla necuametla xihuallacatla cuillotla çacatla yxtlahuacan tepetla atlauhtla\"\n",
      "Processed input 71: \"Axcan domingo yc 10 metztli octubre de 1610 años yquac omonamicti yn tlacatl don Antonio Valleriano telpochtli oquimonamicti yn cihuapilli doña Bárbara çan ihuayolcatzin ynin omoteneuhque yccatotonhuan yn tlacatl don Diego de Alvarado Huanitzin tlahtohuani catca Tenochtitlan\"\n",
      "Processed input 72: \"IIII Acatl xihuitl 1431\"\n",
      "Processed input 73: \"Ypan in yquac momiquilli yn totlaçotatzin fray Alonso de Molina Sant Francisco teopixqui totemachticatzin catca\"\n",
      "Processed input 74: \"Yei axoxtlantli\"\n",
      "Processed input 75: \"anmohuaxcahuan\"\n",
      "Processed input 76: \"Auh ynic cenca huecahuaque ynic ompa catca yn Aztlan Teoculhuacan yn chichimeca totolimpaneca ontzonxihuitl ypan caxtolpohualxihuitl ypan yepohualxiuhtique ynic nimann ompa hualolimque huallehuaque ynic ohualnenenque\"\n",
      "Processed input 77: \"Tlazohcamati huel miac Canin cualli niquincohuaz in painpepeyoctin \"\n",
      "Processed input 78: \"Testigo Francisco de Luna namique ytlaxilacaltiyan San Martin Atezcapan macoc juramento ypaltzinco yn totecuyo dios yhuan yn ciuapilli Sancta Maria yhuan yn ymachiyo Santa Cruz onca tlatlacoltiloc ynic melahuac quitoz yn tlein tlatlaniloz yn tla melahuac quito yquimotlaocoliliz yn dios yn tlacamo mictlan quitzacuctiaz auh yn yehuatl yuh quito ynic me F112v lahuac quitoz\"\n",
      "Processed input 79: \"Auh no yhui yn izquican teopan monasterios yn oncan moyetzticate teopixque frayles  165 huel yzquican no ypampatzinco tlatlatlauhtiloc yn omoteneuhtzino teoyotica tlahtohuani arçobispo auh çanno yhui yn izquican teopan monasterios monjas tlatlatlauhtiloc huel ce semana yn izquican mixtlapohuiltiticatca Sanctíssimo Sacramento cecemilhuitl ynic amo momiquiliz çan quimochicahuiliz in totecuiyo Dios\"\n",
      "Processed input 80: \"Nican ypan in yn oncan hualmicuanique Tiçayocan mexica oncan cexiuhtique\"\n",
      "Processed input 81: \"Iztatl ixquich in monequiz\"\n",
      "Processed input 82: \"Auh yn o ahcicoquimilhui ycihuahuan\"\n",
      "Processed input 83: \"Auh in calli ca huel imatica quiquetztia in tatli yhuan nantli ylamatzin auh yn oncan tlatua yn axcan moteylhuia in Pedro Mazaquen ca amo yntlatohuaya in tlatohua yhoan Ines Tiacapan zan quellehuia in micacali yn tlen oquitlali in illamatzin catca Maria Xoco inic monamacaz calli ca huel tixpan yn iuh oquitotia yhoan tictequipanohuaya inic omococohuaya yxquichin yn itlatul in testigos yc oquineltili oquitlali yn ifirma Pedro Hernandez\"\n",
      "Processed input 84: \"Testigo Miguel Uitztecpancatl ychan San Sebastian Zacatla omonamicti yn isquich cauitl ye nemi ye epoualxiuitl ye oncastoli xiuitl o macoc juramento ynic otlatlacoltiloc ynic amo yztlacatiz\"\n",
      "Processed input 85: \"Ce kilo pelencoznanacatl\"\n",
      "Processed input 86: \"Ipan tlacualchihualoyan tlanahnamiqui ihuan tlacaxitlpahapaca\"\n",
      "Processed input 87: \"Nican ypan in yn quitlalcahuique yn imaltepeuh yn tlalhuacpaneca ynic motecato yn Quauhximalpan oncan oxiuhtique niman noceppa callacque yn Atzaqualloyan yn quauhnepantla\"\n",
      "Processed input 88: \"Onkak kajfentaj uan milaj\"\n",
      "Processed input 89: \"Amo monamaka\"\n",
      "Processed input 90: \"Si no se siembra no se da\"\n",
      "Processed input 91: \"manxitlanamacan\"\n",
      "Processed input 92: \"Quimilhuiaya Totecuiouané ma ysquich Tle amailia Motolinia maceualli cuix ychimal cuix ymaquauh yetinemi Ca mopetlauiltitinemi\"\n",
      "Processed input 93: \"Auh yn oquicacque mexica niman ye yc choca auh niman ye noceppa oncan quimilhui yn diablo Huitzillopochtli Maca ximotequipachocan tla toncuicacan\"\n",
      "Processed input 94: \"Huetztoc oquicuallique yn ixayac atlan chaneque oncan yn ichan yhuino anoço yvinonamacayan Morexón Temaztitlan yn quimictique çan quicocohuitecque yca ce gadana çan ihuayolque yn tleyca quimictique cholloque\"\n",
      "Processed input 95: \"ihuaxca\"\n",
      "Processed input 96: \"Auh yn monasterios teopixcan mochi sepo candelas ynteopantlapanticpac tlatlatlac yn iuh mochi tlacatl oquittac\"\n",
      "Processed input 97: \"Ome axoxtlantli\"\n",
      "Processed input 98: \"Itakilo se kikua de oksik se kiteki uan iujki se kikua ya\"\n",
      "Processed input 99: \"\tAuh ye oncan im monauatique in ic mocentlalique quihtoque\"\n",
      "Processed input 100: \"Inin xiuhpan ompehua in motocayotia Cristerosme inyaoyo\"\n",
      "Processed input 101: \"Ijuak se kimeua xochiyojtok\"\n",
      "Processed input 102: \"Yoan nicteneua centetl huapalli achi uey teixiptla yeuatl yn oncan hycuiliuhtoc transfiguracion yaz nican Santiago azo cana maniz yeuan quimomachitia in padreme\"\n",
      "Processed input 103: \"Mopaca in nacatl ihuan mocuacualatza ixquichcauh in ye tlahuicxitilli in catarinahnanacatl in ye tlachipauhtli motlalia ipan caxitl ihuan motlapachoa inic ihpotochuicciz intla monequi inin huel motlaliliz cenxumalli pitzochiyahuizotl ihtic in xoxocton motlalia ce tecontontli ihuan tlaheo atl ihuan ompa cuacualacaz in tomatl chilli axox ihuan xonacatl Ihcuac mochi ye tzapotic ye moteci ihuan ye motlalilia in catarinahnanacatl ica nacatl ihuan iztayutl Ma cuacualaca cempoalli ahnozo cempoalli ihuan mahtlactli minuto\"\n",
      "Processed input 104: \"Ca quiahuac caucualtzin in calli amo ihquion ca tlahtic\"\n",
      "Processed input 105: \"Yc niman altar mayor omotlancuaquetzato yn tottatzin chocatia quihtotia Macamo ximotequipachocan yn anmexica ca nel aocmo anquimottitillani yn tetl yn quahuitl ma nehua nictzaqua ynic niman oncan oyah in temimiltitech yn oncan otequetzaya yn otepinauhtiaya huel quinahuatequito yn temimilli oncan ye mohuitequi quilhuia fiscal Xinechhuitequi\"\n",
      "Processed input 106: \"Onentacicotonquizaco in tlalticpac\"\n",
      "Processed input 107: \"Tla tehua tiezquia\"\n",
      "Processed input 108: \"Auh no yquac yn ipan in xihuitl yancuica quintequiuhti tlahuillantli yn chalca yn Tiçocicatzin ompa mohuillan yn Popocatepetl ynacaztlan ytocayocan Xochiquiyauhco ynin huel huey quahuitl yn mohuillan\"\n",
      "Processed input 109: \"Tein istak xiktijtiltik uan exot tsikitsitsin uan istaket yej ijistak\"\n",
      "Processed input 110: \"anentlaxia\"\n",
      "Processed input 111: \"Auh yn oyuh quizque matlacxiuitl omey yn quiztinenque y nequametitla yn tziuactla\"\n",
      "Processed input 112: \"Auh yn omoteneuh Totoltecatl Tzompachtli Tlayllotlacteuhctli ca ça onacico yn oncan atentlipan oncan momiquillico yn ça ya yehuatl ypan in omoteneuh yn VI Tochtli xihuitl 1238 años auh ynic tlahtocat ynic mocenpohua cenpohualxihuitl Tiçatepec matlacxihuitl Cuitlatetelco yc mochi cenpohuallonmatlactli xihuitl yn intlahtocauh catca heztlapictin tenanca\"\n",
      "Processed input 113: \"Opehque zan niman quixexeloa premios de tlen oc hualoquizque ipan occe xihuitl otipanoque Ihuan onechmacaque ce diploma cano icuilactaya  NEHUATL NIPORFIRIO DIAZ ALTEPETL MEXICO IPAN ITOCA TOTLALNANTZIN NICTEXEXELHUIA INIMEQUEZ MEDAYATIN IPAMPA MOMACHTIA COCONE ONCUAN ON AIH QUILCAHUAZQUE TLEN QUINMACA IN TZONTECO CUALI MOMACHTIA\"\n",
      "Processed input 114: \"Mochiua kampa kitokaj\"\n",
      "Processed input 115: \"Tleynmach quinequi immitzin moyollotzin immonacayotzin ca yuhqui in nopampa oticmotzacuiltitzino in yc otinechmozcaltili In nextitlan in tlecuillan in nopan oticochyayaticatca intla xinechmotencopiniliani intla xinechmocochpachilhuiyani ca huel nopampa otimoteputzmamauhtitzino in aihuiyan cochiztli in nctequiztli in oticmuchihuili in huel nopampa otimixtozohualtitzino yhuan in naxix in nocuitl oticmatzolhuiticatca In aihuiyan in ahicemele in ohualchiahuatia in ohualpepeyocatia im mochichihualayotzin in nocamac otinechmotetequilili otinechmochichipinilili\"\n",
      "Processed input 116: \"Auh yn oyuh ye ontzonxihuitl ypan matlacpohualxihuitl ypan matlactli onnahui xihuitl cate yn onca anepantla aytic yn ipan mitohua motenehua hueycan altepetl ciudad Aztlan in yehuantin huehuetque chichimeca yn ye motenehua azteca auh yn iuh quitohua huehuetque yn iuh quimachiyotitihui Ce Tecpatl xihuitl ypan yn intlapohuatl auh ynic quinamiqui yn totecuiyo Dios yxiuhtzin ya yehuatl in yn tlacpac neztica de 1064 oyuh ye ontzonxihuitl ypan matlacpohuali ypan epohualli onnahui xihuitl motlacatillitzino y nelli Dios ypiltzin yn iquac oquinnotz yn inteouh in yehuantin azteca ynin achto yc quinnoch ynic çatepa oquimoteotique\"\n",
      "Processed input 117: \"Auh yuh oquihtoque in huehuetque españolesme ayc iuhqui omottac ce visurrey yn nican Mexico ynmacace iuhqui oquichiuh in ye nepa achtopa otlahtocatico visurreyesme nican Mexico yn iuh yehuatzin oquimochihuili don Juan de Mendoça y Luna marqués de Montesclaros\"\n",
      "Processed input 118: \"Se kitoka majmakuil oso najnaui taoltsitsin uan kemaj se kitajtanilia taltikpak uan todios uan kuali mochiuas\"\n",
      "Processed input 119: \"yece zan ichan in tlatlaya amo youalnepantla oc achi tonatiuh icuac in ye on motzcalo on mopiloa tonatiuh quitlatiaya\"\n",
      "Processed input 120: \"Tlazohcamati huel miac\"\n",
      "Processed input 121: \"Auh yn Tlalmanalco ytoca Toçanteuhctli yn oquinmotenpotica yn cuezconpixque yn oquihualmatque yn ya hui yn Chalco tlahtoque yc cenca tlaltecuin\"\n",
      "Processed input 122: \"Yuh motlanahuatilia in tlatohuani gobernador juez yhoan jueces ynic juramento conanazque yni quineltilizque in intlatol yxpan muchihuaz in Pedro Jeronimo regidor mayor yoan Pedro de San Francisco regidor yuh motlanahualtilique yc oquimoneltililique oquimotlalilia in infirmatzin Antonio Valeriano Toribio Lucas Francisco Martin alcalde Miguel Sanchez juez Paso ante mi Diego Leonardo escribano\"\n",
      "Processed input 123: \"Nima yc quitoa Tezozomoctzi quintlatlauhtia quimilhui Oanquihiouique mexicaé oantlacnellique\"\n",
      "Processed input 124: \"Domingo a 26 de abril yquac quimonpehualtique yn ocellome Castillan quinhuicaque onteme tecpan comonidad manca\"\n",
      "Processed input 125: \"XII Calli xihuitl 1257\"\n",
      "Processed input 126: \"Tla nehua oniezquiaya\"\n",
      "Processed input 127: \"Ye temohua ipiltzin xoxopan in ompa temoya in Ipalnemohuani\"\n",
      "Processed input 128: \"in piltzintli in huehuentzin\"\n",
      "Processed input 129: \"Zanno ihcuac tlahcuiloaya ompa Caxtillan in itauhcayo don Bartolomé Esteban Murillo\"\n",
      "Processed input 130: \"In matsaj sesek\"\n",
      "Processed input 131: \"Axcan sábado yn ic 8 mani metztli de diziembre de 1612 años huel ypan ylhuitzin totlaçonantzin Comsepción yhcuac cenca tlamahuiztililiztica tlayahualoliztica quitocaque coztic teocuitlatl yn teopixque San Francisco ypan yn commissario fray Juan Çurida yn ompa totlaçonantzin Sancta María motenehua de la Redonda Cuepopan ynic otlamachiyotique yn oncan opeuh yc otlatlallanoc ynic ye mochihua yancuic tlatlapolloyan portería yn oncan mochihuaz missa yn oquic mochihuaz yancuic cochiantli yhuan yancuic teopancalli yntlatquitica yn teopixque ye quimochihuilia xitiniz yn teopançolli\"\n",
      "Processed input 132: \"XILEX\"\n",
      "Processed input 133: \"Ompa onnecia in ilhuicatl in cicitlaltin in mamalhuaztli Auh in Motecuzoma cenca quimotetzahui in icuac quimittac cicitlaltin ihuan mamalhuaztli\"\n",
      "Processed input 134: \"Monamaka ika tamachiujtsin\"\n",
      "Processed input 135: \"Ipal Laterannenonotzalli otzintic tlahtocayotl in itoca Vaticano\"\n",
      "Processed input 136: \"Ce Tetzcoco conmotlalilia ynic ompa teoyotica sacramentotica quinmocuitlahuitiuh yn ixquichtin umpa onoque yn ompa chanchihua españoles aocmo yehuantin frayles teoyotica sacramentotica quinmocuitlahuizque quinmoquixtililia yn españoles auh ça techixcahuizque yn frayles timacehualti techmocuitlahuizque\"\n",
      "Processed input 137: \"Iuan in tlaquechpanyotl iuhqui almatica amatl in tlacuillolli iuan ipozolcac\"\n",
      "Processed input 138: \"In nonoya ye ichan ninopolihui\"\n",
      "Processed input 139: \"Auh uel iuh cemilhuitl in calacoua in nepielo aocmo nehtotilo Im mocauaya cuicatl zan tlacualizpan\"\n",
      "Processed input 140: \"Oyhuin in quinpeuhque yn tepaneca yn coyohuaque ypan in xihuitl polliuh altepetl Coyohuacan\"\n",
      "Processed input 141: \"Quizqui yn Ome Calli xihuitl\"\n",
      "Processed input 142: \"Auh ynic quimonectiaya tlahtocayotl Huetzin yn oncan Culhuacan ca oncan cihuapilli oncan yehuac yn inantzin ytoca Coatetl ompa quichiuihto tlahtohuani Cohuatlichan yn itoca Ytzmitl yn icontetl ytoca Tlacoxinqui ynin yancuican tlahtohuani mochiuh yn Cohuatlychan\"\n",
      "Processed input 143: \"Auh ynin tlalli ynic uiac nappoalquauitl auh ynic patlauac zan necoc yxquich yoan uel ic toyollopachiuh yn titechmaca tomines cempoalli onchiquacen pesos uel tomatica tococui yn tehoanti don Balthazar Tlillancalqui yoan yn nonamic Juana Tlaco\"\n",
      "Processed input 144: \"Se kikua in itakka in semi uelik\"\n",
      "Processed input 145: \"Auh in nelli mexica in noxhuihuan cecentecpantica ontecpantica in huehuehtichimalli xochitl tomac onmania\"\n",
      "Processed input 146: \"Amo queman tocuapoloz q u e h quihtoznequi huel tiyolchicahqueh\"\n",
      "Processed input 147: \"in ic amo oquitlazotlaque in intzontecon in imelchiquiuh ca amo cacuíque quinencuique in oquittaque in tachcauhyotl in ueueyotl in ic ye petlati ye icpalti in ic ye contlaneui in ipetl in imicpal in puchteca\"\n",
      "Processed input 148: \"In no se kikua in itakka uan no kualtia para pajti\"\n",
      "Processed input 149: \"Ce mamahpicton yepazohtli\"\n",
      "Processed input 150: \"Ynic monamacaque yn huehuetque mexica ynic motenehua yn quahuitl onactiaque ynquauhcozqui yetia ynic huicoque y nohuian yn altepetlypan\"\n",
      "Processed input 151: \"Axcan lunes yn ic 13 mani metztli henero de 1614 años yhcuac yohuatzinco yn omixiuh yn cihuapilli virreyna doña Mariana Riedre marquesa cihuatl yn quichiuh ytoca doña Brianda ycome ypilhuantzitzin in ye quinchihua nican ciudad Mexico yn ipilhuantzitzin tlahtohuani visurrey don Diego Fernández de Córdova marqués de Guadalcáçar\"\n",
      "Processed input 152: \"In chololiztli icuic\"\n",
      "Processed input 153: \"Auh yn axcan ye ycomilhuitl yn ipan martes sancto omoteneuh yn ic 17 mani metztli abril yhcuac nican caltenco San Antón Xolloco ypan hueyotli omotlallico miequintin yaotiacahuan soldadostin españoles yn oyaotlapiaco tlahuiztica no yhui yhuan yn ipan hueyotli Tepeyacacpa yahticac Coyonacazco no miequintin yn oncan motlallito soldadostin no yhui yn ipan ohtli Chapoltepecpa yahticac oncan calyacac temetzcruztitlan no cenca miequintin yn oncan motlalito  184 soldadostin yhuan ynic nohuiyan yzqui ohtliypan hualcallaqui ciudad Mexico huel yzquican ye yaotlapiallo ça ce ynic nohuiyan in yahualiuhcan yn icaltenyoc yxquich yc ciudad Mexico\"\n",
      "Processed input 154: \"Auh ca itech tacitiuh itech tipachitiuh itech timotzotzonatiuh in temamauhtia atl in yuhqui zoloni in yuhqui tetecuicatiuh xaxamacatiuh ic yauh\"\n",
      "Processed input 155: \"Auh yn ipan Sant Juan Baptista ylhuitzin quiz yquac cenca yequene chicahuac yccen peuh yn momanaco quiyahuitl yn cecemilhuitl yhuan ceceyohuatl ye quiyahui ynic nohuian ypan Nueva España ynic ye no nicuel opeyonico otemico atl nican Mexico yn iccennohuian Ahuatzalpan huehuey ayxtlahuacan omochiuh yhuan yn mochi chinamitl huel popoliuh yn apachiuh\"\n",
      "Processed input 156: \"Moztla nican aciz\"\n",
      "Processed input 157: \"Ac inaoc timochintic ahuiltizquetic huellamachtizqueMoyocoyatzin\"\n",
      "Processed input 158: \"Yn oyuh omic Tlotepetl nima ye conixquetzque yn Quauhtliquetzqui yee quiualyaca mexica\"\n",
      "Processed input 159: \"Xochiyoua itech agosto\"\n",
      "Processed input 160: \"In anozo tototl ipan quizaz teocuitlatl niman yuh mocuicui iuh moxima in teculli inic mihuiyotia matlapaltia mocuitlapiltia mocxitia\"\n",
      "Processed input 161: \"Onkak eyi taman se taman kiluiaj xokoyolin se taman tekosej uan se pesojxokoyolin\"\n",
      "Processed input 162: \"Testigo Thoribio Chichimecatl ychan Sanc Sebastian Zacatla in ixiuhtlapohual yehepohualxihuitl on castolli on nahui oquichiuh juramento inic otlatlacoltiloc ynic amo yztlacatiz ypaltzinco dios yhuan Sancta Maria yhuan Sancta Cruz Auh yn tla tiztlacatiz ca diablo quihuicas yn maniman\"\n",
      "Processed input 163: \"Ompoalli ihuan chicueyi centavoh zan ihqui tlacamo onyetiz octepitzin macuilli gratnoh\"\n",
      "Processed input 164: \"Auh ca yuhqui hin yn oquipehualtique yaoyotl ynic peuh çan quihuallitlan chinamitl yn Maxtlaton tlahtohuani yn Azcapotzalco\"\n",
      "Processed input 165: \"Auh inic oconmocaquitique yn imelahuaca tlatolli niman omotlanahuatillique ma oc mochiya in tlatolli azo aca ytla quitoquih in itechpa calli tlalli yuh omotlanahuatillique quimotlalilique in infirmatzin Antonio Valeriano Miguel de los Angeles alcalde Martin Xuarez alcalde Pasó ante mi Francisco Maldonado escrivano\"\n",
      "Processed input 166: \"Auh yn axcan omoteneuh ypan cemilhuitl viernes ynic omixtlapachoca yca metztli tonatiuh ynic mihtohua oqualoc tonatiuh\"\n",
      "Processed input 167: \"In ixpan tonquizatiuh ahcazo mihicoltiz ye Huexotzinco Xayacamachan in Tetzmelocan Nicihuatl ninomaoxihuia ninocxihuia nocon acico ye nochcue ye nochhuipil niccecentlamitaz Niquimelehui Xaltepetlapan ye huexotzinca tzon in Cuetlaxtlan malin tzon in cuetlaxtetecuecuex niccecentlamitaz ln quen oc zan in tlamati Nechmitlania in conetl in tlatohuani in Axayacaton tle on in ma ic tepal no chachahuatlalia Noca titlaomepiaz noconetzin\"\n",
      "Processed input 168: \"Nochi kualtia se kichiua panelaj in eyi taman\"\n",
      "Processed input 169: \"Ce mamahpicton cilantro\"\n",
      "Processed input 170: \"VIII Tochtli xihuitl 1474\"\n",
      "Processed input 171: \"Nican ypan in in ye yuh onpohualxihuitl onmacuilli cate yn nican Tenochtitlan yn mexica ynic acico chichimeca mexitin colhuaque\"\n",
      "Processed input 172: \"XI Calli xihuitl 1477\"\n",
      "Processed input 173: \"Auh in icuac in onmotemacato in Cuauhtemoctzin njman quihuicaque in Acachinanco in ye yoa Auh in imuztlayoc in ie achiton tonatiuh ie no ceppa huallaque in españoles huel miequintin No zan yuh tlantihuitze in moyauchichiuhtihuitze tepuzhuipilli in tepuzcuacalalatli Auh aoc tle in intepuzmacuauh ihuan aoc tle in inchimal\"\n",
      "Processed input 174: \"Auh y mach yehuatl yn inauatil y Uitzilopochtli cayatle uetzi\"\n",
      "Processed input 175: \"No yquac poliuhque toltitlancalque\"\n",
      "Processed input 176: \"in nican onoc in ixhuatoc\"\n",
      "Processed input 177: \"Auh quimilhui yn Quetzalcanauhtli Ohuaquimocnellilique yn amoteouh yn amotlahtocauh ma tihuiyan\"\n",
      "Processed input 178: \"Yehua iquechcuahyoilpilli iztaqueh ihuan texohqueh quinpiah\"\n",
      "Processed input 179: \"titlanamacazquiaya\"\n",
      "Processed input 180: \"Niman quihtoque yn chalca acxoteca Ca ye cualli ca amechmocahuilitihui\"\n",
      "Processed input 181: \"Yc niman oncan quintlaocollique yn tlalli cenca huey yn quicauh yn Atonaltzin yn itlamacehual auh yn Quahuitzatzin yn quicauh yn tlalli yn itlamacehual çan quexquichca tlacatecolloythualco yn quizticaca yn tenanca tepantli yn Tequanipan\"\n",
      "Processed input 182: \"Ipampa inon ocachi cualli in tlen amotepacti mochihua amo zazan tic malhuizqueh\"\n",
      "Processed input 183: \"Auh nahui yn estandarte tliltic tlayacantiaque ome yztac teocuitlatl plata  241 yn icruzyo tlanepantla mantiaque auh necoc yntloc mantiaque quintzatzacuitiaque yn ocome omoteneuh estandarte çan cuahuitl teocuitlayo yn icruzyo\"\n",
      "Processed input 184: \"Nochi xiuit saj\"\n",
      "Processed input 185: \"XII Tochtli xihuitl 1322\"\n",
      "Processed input 186: \"Kampa etayij uan kikixtijkej ya in et kemej in yekintsin tapaniantiak euati ya\"\n",
      "Processed input 187: \"Tlahcoxonacatl ahmo huehyi\"\n",
      "Processed input 188: \"44\tYhuan huel xicuica huel xitlahto huel xitenotza huel xitenanquili huel xitetlatlauhti ahmo tlacohualli in tlahtolli Ma yuhqui in tinontli in tixolopitli timocuep Yhuan immalacatl in tzotzopaztli huel xicmocuitlahui in tlalchihuic in acohuic in potoncatzintli in pillincatzintli in tlamacehualtzintli yhuan in tlacuiloltzintli immachiotzintli in tlapaltzintli Yc huel tetloc tenahuac timonemitiz inic ticmomahcehuiz in cana achitzin atolatzintli in tlamatzohualtzintli in quiltzintli in nopaltzintli yhuan in can quexquitzin xaxaltzintli in popoltzintli immoquezpantzinco immoquechtlantzinco ompilcaz inic ontotoniaz inic onyamaniaz immotlactzin immonacayotzin inic ipan ticmotlazocamachitiz in Totecuiyo in itetlaocolilitzin in iteycnelilitzin\"\n",
      "Processed input 189: \"Auh in ye yuhqui in o tlacencauh ye mochi nez ixquich omoteneuh in omito niman ye im om peua in Tochtepec in ompa cem onoque in puchteca in oztomeca in ye nouian altepetl ipan in ye nouian altepetl ipan tlaca oncan cem onoca in ical\"\n",
      "Processed input 190: \"Auh ypan in yn xihuitl yn oquipehualti in ye quinmitlanillilia inhuellitzin yhuan yntepallehuillitzin yn tlahtoque don Fernando yhuan doña Isabel ynic huallaz nican ypan Nueva España ynic quinextiquiuh yancuic tlalli yn intechtzinco pohuiz tlahtoque España\"\n",
      "Processed input 191: \"Ynic mitohua yn ihquac acico yn intlamaceuhcauh yn Tequanipan tlaca yn itoca Tziuhtlacauhqui cihuatl yn quihualhuicac ymecauh catca yn Tliltecatl huallotztita yn ihtic hualyetia cihuatl yn piltontli ypiltzin yn Tliltecatl in yachcauh catca yn Atonaltzin ca Huexotzincopa yn hualtemoque\"\n",
      "Processed input 192: \"Çano ypa Ce Tochtli xiuitl yn quitlatlauhtito y mexica yn Teçoçomoctzi ynic quitlanito yn ipiltzi yn intlatocauh mochiuh conilhuia Nopiltzintziné tlatouanié techualliuaque y motechiuhcaua mexica ueuetque ca conitoa Ma quimocaquiti tlacatl Motolinia y mocolhua ca titoteutiznequi ca tictomaco y mocozqui moquetzal\"\n",
      "Processed input 193: \"Yhuan ynic nohuian yhtic ciudad yn incalticpac castilteca nohuian quitlatique quahuitl yhuan nohuian tlatzitzillitzalloc yn izquican teopan Mexico yn monasterios\"\n",
      "Processed input 194: \"Komo kajfentaj kimeua pero komo kuoujijtik amo akaj kimeua\"\n",
      "Processed input 195: \"In cihuacalehcapo quipia conte calli\"\n",
      "Processed input 196: \"Chicuey Tecpatl anotle mochiuh\"\n",
      "Processed input 197: \"Nican ypan in quinpeuhque Xicochimalco tlaca auh çanno yquac quinpeuhque poliuhque yn xaltepeca yhuan totomihuaque\"\n",
      "Processed input 198: \"In alotl icpac in cuacuahuitl ca\"\n",
      "Processed input 199: \"Auh in yequene yhquac in ye ynma in ye tlayohuaz in ye ome tzillini ypan tlaco hora yc niman opeuh in ye miquania mixtli in ye quitlalcahuia tonatiuh ynic mochi tlacatl huel quittaz yn quenin ipan ye mochihuaz tonatiuh achi hueca yc quitlalcahui tlanahuac çan huel hualmoyecyahualiuhcatecato yn mixtli ynic quitlacahuilli tlanaliuhtiquiz yn ilhuicatitech ynic huel cempani iyoca hualtlalli tonatiuh\"\n",
      "Processed input 200: \"Yn isquich cauitl otlamico in tlatolli ontetl metztli yn isquich cauitl otlamico yn informacion etc\"\n",
      "Input embeddings guardados en input_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def get_input_embeddings(prompt, model, tokenizer, max_seq_length=256):\n",
    "    # Determinar el dispositivo\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Tokenizar el prompt\n",
    "    inputs = tokenize_prompt(prompt, tokenizer, max_seq_length)\n",
    "\n",
    "    # Mover los inputs al dispositivo\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Pasar el input por el modelo sin generar texto\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "\n",
    "    # Extraer los embeddings de la última capa oculta\n",
    "    embeddings = outputs.hidden_states[-1]\n",
    "\n",
    "    # Promediar los embeddings a lo largo de la secuencia (opcional)\n",
    "    averaged_embeddings = embeddings.mean(dim=1)\n",
    "\n",
    "    # Convertir a float32 antes de pasarlos a NumPy\n",
    "    return averaged_embeddings.cpu().float().numpy()\n",
    "\n",
    "def process_input_embeddings(dataset_path, model, tokenizer, max_seq_length=256, output_csv='input_embeddings.csv'):\n",
    "    # Cargar el dataset y seleccionar la tercera columna\n",
    "    dataset = pd.read_csv(dataset_path)\n",
    "    third_column = dataset.iloc[:, 2]  # Seleccionar la tercera columna\n",
    "\n",
    "    # Lista para almacenar los embeddings de entrada\n",
    "    all_input_embeddings = []\n",
    "\n",
    "    # Iterar sobre los primeros 20 inputs de la tercera columna\n",
    "    for index, input_text in enumerate(third_column.head(200)):\n",
    "        prompt = input_text  # Utilizar el texto de la tercera columna como prompt\n",
    "\n",
    "        # Obtener los embeddings del input\n",
    "        input_embeddings = get_input_embeddings(prompt, model, tokenizer, max_seq_length)\n",
    "        \n",
    "        # Agregar los embeddings a la lista\n",
    "        all_input_embeddings.append(input_embeddings.flatten())\n",
    "\n",
    "        print(f\"Processed input {index + 1}: {prompt}\")\n",
    "\n",
    "    # Guardar los embeddings de entrada en un nuevo archivo CSV\n",
    "    input_df = pd.DataFrame(all_input_embeddings)\n",
    "    input_df.to_csv(output_csv, index=False, header=False)\n",
    "    print(f\"Input embeddings guardados en {output_csv}\")\n",
    "\n",
    "# Ejecutar la función para procesar los input embeddings de la tercera columna\n",
    "process_input_embeddings('dataset.csv', model, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El promedio de la distancia coseno es: 0.22025931930152842\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def calcular_promedio_distancia_coseno(embeddings_csv1, embeddings_csv2):\n",
    "    # Cargar los dos archivos CSV de embeddings\n",
    "    embeddings1 = pd.read_csv(embeddings_csv1, header=None)\n",
    "    embeddings2 = pd.read_csv(embeddings_csv2, header=None)\n",
    "\n",
    "    # Asegurarse de que ambos tengan el mismo número de filas\n",
    "    num_filas = min(len(embeddings1), len(embeddings2))\n",
    "\n",
    "    # Lista para almacenar las distancias coseno\n",
    "    distancias_coseno = []\n",
    "\n",
    "    # Iterar sobre las filas y calcular la distancia coseno\n",
    "    for i in range(num_filas):\n",
    "        vector1 = embeddings1.iloc[i].values\n",
    "        vector2 = embeddings2.iloc[i].values\n",
    "\n",
    "        # Calcular la distancia coseno entre los vectores\n",
    "        distancia = cosine(vector1, vector2)\n",
    "\n",
    "        # Agregar la distancia a la lista\n",
    "        distancias_coseno.append(distancia)\n",
    "\n",
    "    # Calcular el promedio de las distancias coseno\n",
    "    promedio_distancia = sum(distancias_coseno) / len(distancias_coseno)\n",
    "\n",
    "    # Mostrar el promedio\n",
    "    print(f\"El promedio de la distancia coseno es: {promedio_distancia}\")\n",
    "\n",
    "# Ejecutar la función para calcular el promedio de la distancia coseno\n",
    "calcular_promedio_distancia_coseno('output_embeddings.csv', 'input_embeddings.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "023eff5ca8f84904b4211d59458df8de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "027f7ba29d494073ad7ee49ae01dbc23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "091bc142327b49fdbba6d695641ed587": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "099625ffae9846be87f68b3649b6c838": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "112132ae410a40e188a25d968f8ac659": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8179f044fd7b46aeaa30d71fa19419f8",
      "placeholder": "​",
      "style": "IPY_MODEL_e42e3136e67444789888ef98f3debe19",
      "value": " 21084/21084 [00:02&lt;00:00, 8111.89 examples/s]"
     }
    },
    "1550ee2d3de64537b726e30154f53bce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "169a834157484941be504adfe5b731d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1bd9fbb89ddb49ae92c3a13ffc76cbef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1c7ccad9c9fa46a5b433f24c8173c727": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f5a55aa3b8964bbcb602b2656286801b",
       "IPY_MODEL_74011c42474f496bbac9fbde8684fd00",
       "IPY_MODEL_7b6aa54e66bb491b88bb8bbd634064c4"
      ],
      "layout": "IPY_MODEL_74747322bb8a49edae82904fe24370b4"
     }
    },
    "1f642765247b4b4ebabf021dc3af5ae9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f1a9c88f77d746daae04cb2f306bcbed",
       "IPY_MODEL_f82ae39e0302414a84ad1c5eedfd0232",
       "IPY_MODEL_112132ae410a40e188a25d968f8ac659"
      ],
      "layout": "IPY_MODEL_4d24b48da3fa47008c6fce46fe6e3f6c"
     }
    },
    "2cac19210c9a48e5ae2c4bdb95837cd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61ca62aa9988427294343613050e8301",
      "placeholder": "​",
      "style": "IPY_MODEL_6fc8487d56a84c29a95ac506516c2b64",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "2d5a3e9844e64a28b410cb32143b8147": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32f46fe8a5964432846decb0a1ef6c7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "34331f790f3d4a98b34ac22dabc13a69": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39266f36fbed42a28837c5964a4348d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d5a3e9844e64a28b410cb32143b8147",
      "placeholder": "​",
      "style": "IPY_MODEL_824ae29b7b85472192b2d57ba9835d68",
      "value": "Map: 100%"
     }
    },
    "3ec446278d744d88b9dbdc3afeb5e582": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a459ea2df874a8194025f2715e92bc8",
      "placeholder": "​",
      "style": "IPY_MODEL_a159738bb1034fa290a37ff107b03c27",
      "value": " 454/454 [00:00&lt;00:00, 21.1kB/s]"
     }
    },
    "460de3366aa14a4f919b2bbc8ec9253b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_099625ffae9846be87f68b3649b6c838",
      "max": 9085657,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fa5ec7baf8344b34800984accedd32c3",
      "value": 9085657
     }
    },
    "4d1739c429e1461db5520228f59d8e3a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d24b48da3fa47008c6fce46fe6e3f6c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ee9752e7c974f1c9fa57d63defd0273": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb0ebba652e54e698f72c561b9aadb16",
      "max": 184,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_765d4bf8045742068279650d8e25335a",
      "value": 184
     }
    },
    "4ef0bbd8aa044edb850bebfb858fc3e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76f2765585ce450881cae910e442d664",
      "placeholder": "​",
      "style": "IPY_MODEL_88792d090d824d1c8ff9207a2b69a1d4",
      "value": " 54.6k/54.6k [00:00&lt;00:00, 3.75MB/s]"
     }
    },
    "4f542ca725fc45b1a48a163fcb6da4a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ab0bfe025f84cf7ac7553806f7188ac",
      "placeholder": "​",
      "style": "IPY_MODEL_767aafdb45d143368ccca8ac4e8c47de",
      "value": " 184/184 [00:00&lt;00:00, 10.7kB/s]"
     }
    },
    "4f54ae54d9d24b8ea27b5828d73449bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6c902674fdf4f5d982129501c4ef36f",
      "placeholder": "​",
      "style": "IPY_MODEL_fbb78609b507419f94e659f45551c3b8",
      "value": " 1.03G/1.03G [00:11&lt;00:00, 334MB/s]"
     }
    },
    "571a5352d5824edba4bda40f4745fcea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d1739c429e1461db5520228f59d8e3a",
      "placeholder": "​",
      "style": "IPY_MODEL_ee5e0354314e4ffda397d534a89770b6",
      "value": "tokenizer.json: 100%"
     }
    },
    "5866b9746e034c2dac999b2c3251bdfb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58955b380e6e480f9f1389d4946a8547": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6188db144400485285a38317454bb19b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61ca62aa9988427294343613050e8301": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ab0bfe025f84cf7ac7553806f7188ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fc8487d56a84c29a95ac506516c2b64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "74011c42474f496bbac9fbde8684fd00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34331f790f3d4a98b34ac22dabc13a69",
      "max": 21084,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1bd9fbb89ddb49ae92c3a13ffc76cbef",
      "value": 21084
     }
    },
    "7418ecc0016c476781399a0db9a7863f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "74747322bb8a49edae82904fe24370b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "754931fc0cc2433091ba1a8579ff2e14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c06a5b3a3044fa9abae49f84e852b9c",
      "max": 1027676737,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_32f46fe8a5964432846decb0a1ef6c7f",
      "value": 1027676639
     }
    },
    "7597f82c689f4b07984176113d6db56a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bc9b7de3b86e4aed9d1da38e854371c1",
       "IPY_MODEL_a2f59b00a353431e931b726e4e4bd96c",
       "IPY_MODEL_4ef0bbd8aa044edb850bebfb858fc3e2"
      ],
      "layout": "IPY_MODEL_ddda6e01f229454fa176f2846a76b57e"
     }
    },
    "765d4bf8045742068279650d8e25335a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "767aafdb45d143368ccca8ac4e8c47de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "76f2765585ce450881cae910e442d664": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a459ea2df874a8194025f2715e92bc8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a9331d27e1343688c3743375e2926a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d86e034517624b77a96dc91abb8630f7",
      "max": 454,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1550ee2d3de64537b726e30154f53bce",
      "value": 454
     }
    },
    "7b6aa54e66bb491b88bb8bbd634064c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6f684f4839642768216fa453e6d2d61",
      "placeholder": "​",
      "style": "IPY_MODEL_169a834157484941be504adfe5b731d7",
      "value": " 21084/21084 [00:06&lt;00:00, 1854.85 examples/s]"
     }
    },
    "8179f044fd7b46aeaa30d71fa19419f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "824ae29b7b85472192b2d57ba9835d68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88792d090d824d1c8ff9207a2b69a1d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89e7055e72b042609eab0eed86be1bba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_091bc142327b49fdbba6d695641ed587",
      "placeholder": "​",
      "style": "IPY_MODEL_b61fbeaa189347418a7bbc6d643b8103",
      "value": "generation_config.json: 100%"
     }
    },
    "89e75bfd2e7443a9b09827d9c35642e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58955b380e6e480f9f1389d4946a8547",
      "placeholder": "​",
      "style": "IPY_MODEL_f9c315759ff04bd4b25502a27de9cd9e",
      "value": " 9.09M/9.09M [00:00&lt;00:00, 38.2MB/s]"
     }
    },
    "8a94a101c0dc4422ac84cb8763cb566b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f0aa09690fef4143aca13913f44cfee1",
       "IPY_MODEL_754931fc0cc2433091ba1a8579ff2e14",
       "IPY_MODEL_4f54ae54d9d24b8ea27b5828d73449bd"
      ],
      "layout": "IPY_MODEL_fcf7564dd7004e46ba3b56fbea0480f6"
     }
    },
    "8b36cff4b3f94bfd8f071eba996e442d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8c06a5b3a3044fa9abae49f84e852b9c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93f0dc2041fc4053b947c5abfe091bf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a0d9cca01e349ed94fb6515fdf236d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a159738bb1034fa290a37ff107b03c27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a2f59b00a353431e931b726e4e4bd96c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cba5cfa885214c63a6b4f25253080ef8",
      "max": 54598,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8b36cff4b3f94bfd8f071eba996e442d",
      "value": 54598
     }
    },
    "a35baa79dc464bf2b77398a6d40d3e18": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6f684f4839642768216fa453e6d2d61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad9bb2cae0d34b94820e2ec5b7f288d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_89e7055e72b042609eab0eed86be1bba",
       "IPY_MODEL_4ee9752e7c974f1c9fa57d63defd0273",
       "IPY_MODEL_4f542ca725fc45b1a48a163fcb6da4a6"
      ],
      "layout": "IPY_MODEL_d21149abf49c4c1e988e0686183a4f42"
     }
    },
    "afd8093f65034bce828d34329e4dd442": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b186a04d94c64c8fad6248251fff69d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b61fbeaa189347418a7bbc6d643b8103": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb96ef3138e2495a83f2d247f41d20f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2cac19210c9a48e5ae2c4bdb95837cd2",
       "IPY_MODEL_7a9331d27e1343688c3743375e2926a3",
       "IPY_MODEL_3ec446278d744d88b9dbdc3afeb5e582"
      ],
      "layout": "IPY_MODEL_d6a3504cd4bb4855b9b1c9bdfe8c4ba0"
     }
    },
    "bc9b7de3b86e4aed9d1da38e854371c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5866b9746e034c2dac999b2c3251bdfb",
      "placeholder": "​",
      "style": "IPY_MODEL_93f0dc2041fc4053b947c5abfe091bf7",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "c3622339b4ac4c81ba242c3ae561a8d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c483bd392fa643db8df04f41dd565601": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_39266f36fbed42a28837c5964a4348d2",
       "IPY_MODEL_e6f68ca87e5a4860878c69a1692eff8c",
       "IPY_MODEL_d4a8a268f8014eda83c4e50aad7ac42c"
      ],
      "layout": "IPY_MODEL_e1a821a2ffa9414aa4bf7c6e32b46b9e"
     }
    },
    "cb8b4795ae82477c92d48fcbd0004dd7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cba5cfa885214c63a6b4f25253080ef8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cdf3d68b36d74b4c80fd7856a2cd206d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cff85b3c1f51411b850894aed973afba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d21149abf49c4c1e988e0686183a4f42": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4a8a268f8014eda83c4e50aad7ac42c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb8b4795ae82477c92d48fcbd0004dd7",
      "placeholder": "​",
      "style": "IPY_MODEL_023eff5ca8f84904b4211d59458df8de",
      "value": " 21084/21084 [00:00&lt;00:00, 47567.07 examples/s]"
     }
    },
    "d58a9ae1ee144a5d84ca23e26a1d20e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d6a3504cd4bb4855b9b1c9bdfe8c4ba0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d86e034517624b77a96dc91abb8630f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db97b6f6ddea440fb1a132dabd55e657": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_571a5352d5824edba4bda40f4745fcea",
       "IPY_MODEL_460de3366aa14a4f919b2bbc8ec9253b",
       "IPY_MODEL_89e75bfd2e7443a9b09827d9c35642e8"
      ],
      "layout": "IPY_MODEL_a35baa79dc464bf2b77398a6d40d3e18"
     }
    },
    "ddda6e01f229454fa176f2846a76b57e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1a821a2ffa9414aa4bf7c6e32b46b9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e42e3136e67444789888ef98f3debe19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e6f68ca87e5a4860878c69a1692eff8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_afd8093f65034bce828d34329e4dd442",
      "max": 21084,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7418ecc0016c476781399a0db9a7863f",
      "value": 21084
     }
    },
    "ee5e0354314e4ffda397d534a89770b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f0aa09690fef4143aca13913f44cfee1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6188db144400485285a38317454bb19b",
      "placeholder": "​",
      "style": "IPY_MODEL_027f7ba29d494073ad7ee49ae01dbc23",
      "value": "model.safetensors: 100%"
     }
    },
    "f1a9c88f77d746daae04cb2f306bcbed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b186a04d94c64c8fad6248251fff69d6",
      "placeholder": "​",
      "style": "IPY_MODEL_d58a9ae1ee144a5d84ca23e26a1d20e6",
      "value": "Map: 100%"
     }
    },
    "f5a55aa3b8964bbcb602b2656286801b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cff85b3c1f51411b850894aed973afba",
      "placeholder": "​",
      "style": "IPY_MODEL_9a0d9cca01e349ed94fb6515fdf236d0",
      "value": "Map: 100%"
     }
    },
    "f6c902674fdf4f5d982129501c4ef36f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f82ae39e0302414a84ad1c5eedfd0232": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3622339b4ac4c81ba242c3ae561a8d9",
      "max": 21084,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cdf3d68b36d74b4c80fd7856a2cd206d",
      "value": 21084
     }
    },
    "f9c315759ff04bd4b25502a27de9cd9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa5ec7baf8344b34800984accedd32c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fb0ebba652e54e698f72c561b9aadb16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbb78609b507419f94e659f45551c3b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fcf7564dd7004e46ba3b56fbea0480f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
